{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d182cc95",
   "metadata": {},
   "source": [
    "# TCGA-BRCA Demo\n",
    "\n",
    "### Dataset Source\n",
    "\n",
    "- **Omics Data**: [FireHose BRCA](http://firebrowse.org/?cohort=BRCA)\n",
    "- **Clinical and PAM50 Data**: [TCGAbiolinks](http://bioconductor.org/packages/release/bioc/html/TCGAbiolinks.html)\n",
    "\n",
    "##### Dataset Overview\n",
    "\n",
    "- **Original Data**:\n",
    "\n",
    "    - **Methylation**: 20,107 × 885\n",
    "    - **mRNA**: 18,321 × 1,212\n",
    "    - **miRNA**: 503 × 1,189\n",
    "    - **PAM50**: 1,087 × 1\n",
    "    - **Clinical**: 1,098 × 101\n",
    "\n",
    "- **PAM50 Subtype Counts**:\n",
    "\n",
    "    - **LumA**: 419\n",
    "    - **LumB**: 140\n",
    "    - **Basal**: 130\n",
    "    - **Her2**: 46\n",
    "    - **Normal**: 34\n",
    "\n",
    "### Patients in Every Dataset\n",
    "\n",
    "- Total patients present in methylation, mRNA, miRNA, PAM50, and clinical: **769**\n",
    "\n",
    "### Final Shapes (Per-Patient)\n",
    "\n",
    "After aggregating multiple aliquots by mean, all modalities align on 769 patients:\n",
    "\n",
    "- **Methylation**: 769 × 20,106\n",
    "- **mRNA**: 769 × 20,531\n",
    "- **miRNA**: 769 × 503\n",
    "- **PAM50**: 769 × 1\n",
    "- **Clinical**: 769 × 119\n",
    "\n",
    "### Data Summary Table\n",
    "\n",
    "| Stage                          | Clinical    | Methylation  | miRNA       | mRNA           | PAM50 (Subtype Counts)                                         | Notes                                   |\n",
    "| ------------------------------ | ----------- | ------------ | ----------- | -------------- | -------------------------------------------------------------- | --------------------------------------- |\n",
    "| **Original Raw Data**          | 1,098 × 101 | 20,107 × 885 | 503 × 1,189 | 18,321 × 1,212 | LumA: 509<br>LumB: 209<br>Basal: 192<br>Her2: 82<br>Normal: 40 | Raw FireHose & TCGAbiolinks files       |\n",
    "| **Patient-Level Intersection** | 769 × 101   | 769 × 20,107 | 769 × 1,046 | 769 × 20,531   | LumA: 419<br>LumB: 140<br>Basal: 130<br>Her2: 46<br>Normal: 34 | Patients with complete data in all sets |\n",
    "\n",
    "### Reference Links\n",
    "\n",
    "- [FireHose BRCA](http://firebrowse.org/?cohort=BRCA)\n",
    "- [TCGAbiolinks](http://bioconductor.org/packages/release/bioc/html/TCGAbiolinks.html)\n",
    "- [Direct Download BRCA](http://firebrowse.org/?cohort=BRCA&download_dialog=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0bda23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-3C-AAAU-01</th>\n",
       "      <th>TCGA-3C-AALI-01</th>\n",
       "      <th>TCGA-3C-AALJ-01</th>\n",
       "      <th>TCGA-3C-AALK-01</th>\n",
       "      <th>TCGA-4H-AAAK-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsa-let-7a-1</th>\n",
       "      <td>13.129765</td>\n",
       "      <td>12.918069</td>\n",
       "      <td>13.012033</td>\n",
       "      <td>13.144697</td>\n",
       "      <td>13.411684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-let-7a-2</th>\n",
       "      <td>14.117933</td>\n",
       "      <td>13.922300</td>\n",
       "      <td>14.010002</td>\n",
       "      <td>14.141721</td>\n",
       "      <td>14.413518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hsa-let-7a-3</th>\n",
       "      <td>13.147714</td>\n",
       "      <td>12.913194</td>\n",
       "      <td>13.028483</td>\n",
       "      <td>13.151281</td>\n",
       "      <td>13.420481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TCGA-3C-AAAU-01  TCGA-3C-AALI-01  TCGA-3C-AALJ-01  \\\n",
       "gene                                                              \n",
       "hsa-let-7a-1        13.129765        12.918069        13.012033   \n",
       "hsa-let-7a-2        14.117933        13.922300        14.010002   \n",
       "hsa-let-7a-3        13.147714        12.913194        13.028483   \n",
       "\n",
       "              TCGA-3C-AALK-01  TCGA-4H-AAAK-01  \n",
       "gene                                            \n",
       "hsa-let-7a-1        13.144697        13.411684  \n",
       "hsa-let-7a-2        14.141721        14.413518  \n",
       "hsa-let-7a-3        13.151281        13.420481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(503, 1189)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-3C-AAAU-01</th>\n",
       "      <th>TCGA-3C-AALI-01</th>\n",
       "      <th>TCGA-3C-AALJ-01</th>\n",
       "      <th>TCGA-3C-AALK-01</th>\n",
       "      <th>TCGA-4H-AAAK-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?|100133144</th>\n",
       "      <td>4.032489</td>\n",
       "      <td>3.211931</td>\n",
       "      <td>3.538886</td>\n",
       "      <td>3.595671</td>\n",
       "      <td>2.775430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|100134869</th>\n",
       "      <td>3.692829</td>\n",
       "      <td>4.119273</td>\n",
       "      <td>3.206237</td>\n",
       "      <td>3.469873</td>\n",
       "      <td>3.850979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?|10357</th>\n",
       "      <td>5.704604</td>\n",
       "      <td>6.124231</td>\n",
       "      <td>7.269570</td>\n",
       "      <td>7.168565</td>\n",
       "      <td>6.395968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TCGA-3C-AAAU-01  TCGA-3C-AALI-01  TCGA-3C-AALJ-01  \\\n",
       "gene                                                             \n",
       "?|100133144         4.032489         3.211931         3.538886   \n",
       "?|100134869         3.692829         4.119273         3.206237   \n",
       "?|10357             5.704604         6.124231         7.269570   \n",
       "\n",
       "             TCGA-3C-AALK-01  TCGA-4H-AAAK-01  \n",
       "gene                                           \n",
       "?|100133144         3.595671         2.775430  \n",
       "?|100134869         3.469873         3.850979  \n",
       "?|10357             7.168565         6.395968  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18321, 1212)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-3C-AAAU-01</th>\n",
       "      <th>TCGA-3C-AALI-01</th>\n",
       "      <th>TCGA-3C-AALJ-01</th>\n",
       "      <th>TCGA-3C-AALK-01</th>\n",
       "      <th>TCGA-4H-AAAK-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybridization REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Composite Element REF</th>\n",
       "      <td>Beta_Value</td>\n",
       "      <td>Beta_Value</td>\n",
       "      <td>Beta_Value</td>\n",
       "      <td>Beta_Value</td>\n",
       "      <td>Beta_Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG</th>\n",
       "      <td>0.483716119676</td>\n",
       "      <td>0.637191226131</td>\n",
       "      <td>0.656092398242</td>\n",
       "      <td>0.615194471357</td>\n",
       "      <td>0.612080370511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CF</th>\n",
       "      <td>0.295827203492</td>\n",
       "      <td>0.458972998571</td>\n",
       "      <td>0.489725289638</td>\n",
       "      <td>0.625765223243</td>\n",
       "      <td>0.507736509665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TCGA-3C-AAAU-01 TCGA-3C-AALI-01 TCGA-3C-AALJ-01  \\\n",
       "Hybridization REF                                                       \n",
       "Composite Element REF      Beta_Value      Beta_Value      Beta_Value   \n",
       "A1BG                   0.483716119676  0.637191226131  0.656092398242   \n",
       "A1CF                   0.295827203492  0.458972998571  0.489725289638   \n",
       "\n",
       "                      TCGA-3C-AALK-01 TCGA-4H-AAAK-01  \n",
       "Hybridization REF                                      \n",
       "Composite Element REF      Beta_Value      Beta_Value  \n",
       "A1BG                   0.615194471357  0.612080370511  \n",
       "A1CF                   0.625765223243  0.507736509665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20107, 885)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcga-5l-aat0</th>\n",
       "      <th>tcga-5l-aat1</th>\n",
       "      <th>tcga-a1-a0sp</th>\n",
       "      <th>tcga-a2-a04v</th>\n",
       "      <th>tcga-a2-a04y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybridization REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Composite Element REF</th>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_to_birth</th>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vital_status</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tcga-5l-aat0 tcga-5l-aat1 tcga-a1-a0sp tcga-a2-a04v  \\\n",
       "Hybridization REF                                                           \n",
       "Composite Element REF        value        value        value        value   \n",
       "years_to_birth                  42           63           40           39   \n",
       "vital_status                     0            0            0            1   \n",
       "\n",
       "                      tcga-a2-a04y  \n",
       "Hybridization REF                   \n",
       "Composite Element REF        value  \n",
       "years_to_birth                  53  \n",
       "vital_status                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18, 1097)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "root = Path(\"/home/vicente/Github/BioNeuralNet/TCGA_BRCA_DATA\")\n",
    "\n",
    "mirna_raw = pd.read_csv(root/\"BRCA.miRseq_RPKM_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)                            \n",
    "rna_raw = pd.read_csv(root / \"BRCA.uncv2.mRNAseq_RSEM_normalized_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)\n",
    "meth_raw = pd.read_csv(root/\"BRCA.meth.by_mean.data.txt\", sep='\\t',index_col=0,low_memory=False)\n",
    "clinical_raw = pd.read_csv(root / \"BRCA.clin.merged.picked.txt\",sep=\"\\t\", index_col=0, low_memory=False)\n",
    "\n",
    "# display all shapes and first few rows of each dataset\n",
    "display(mirna_raw.iloc[:3,:5])\n",
    "display(mirna_raw.shape)\n",
    "\n",
    "display(rna_raw.iloc[:3,:5])\n",
    "display(rna_raw.shape)\n",
    "\n",
    "display(meth_raw.iloc[:3,:5])\n",
    "display(meth_raw.shape)\n",
    "\n",
    "display(clinical_raw.iloc[:3,:5])\n",
    "display(clinical_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacae339",
   "metadata": {},
   "source": [
    "## TCGA-BioLink: Pam50\n",
    "\n",
    "This section demonstrates how to use the `TCGAbiolinks` R package to access and download clinical and molecular subtype data. It begins by ensuring `TCGAbiolinks` is installed, then loads the package. It retrieves PAM50 molecular subtype labels using `TCGAquery_subtype()` and writes them to a CSV file. Additionally, it downloads clinical data using `GDCquery_clinic()` and formats it with `GDCprepare_clinic()`, saving the result as another CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445601f",
   "metadata": {},
   "source": [
    "```R\n",
    "  # Install TCGAbiolinks\n",
    "  if (!requireNamespace(\"TCGAbiolinks\", quietly = TRUE)) {\n",
    "    if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "      install.packages(\"BiocManager\")\n",
    "    BiocManager::install(\"TCGAbiolinks\")\n",
    "  }\n",
    "\n",
    "  # Load the library\n",
    "  library(TCGAbiolinks)\n",
    "\n",
    "  # Download PAM50 subtype labels\n",
    "  pam50_df <- TCGAquery_subtype(tumor = \"BRCA\")[ , c(\"patient\", \"BRCA_Subtype_PAM50\")]\n",
    "  write.csv(pam50_df, file = \"BRCA_PAM50_labels.csv\", row.names = FALSE, quote = FALSE)\n",
    "\n",
    "  # Download clinical data\n",
    "  clin_raw <- GDCquery_clinic(project = \"TCGA-BRCA\", type = \"clinical\")\n",
    "  clin_df <- GDCprepare_clinic(clin_raw, clinical.info = \"patient\")\n",
    "  write.csv(clin_df, file = \"BRCA_clinical_data.csv\", row.names = FALSE, quote = FALSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6eb71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRCA_Subtype_PAM50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>Her2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALK</th>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-4H-AAAK</th>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BRCA_Subtype_PAM50\n",
       "patient                        \n",
       "TCGA-3C-AAAU               LumA\n",
       "TCGA-3C-AALI               Her2\n",
       "TCGA-3C-AALJ               LumB\n",
       "TCGA-3C-AALK               LumA\n",
       "TCGA-4H-AAAK               LumA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1087, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>synchronous_malignancy</th>\n",
       "      <th>ajcc_pathologic_stage</th>\n",
       "      <th>days_to_diagnosis</th>\n",
       "      <th>laterality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submitter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-A7-A0DC</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XG</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IIIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-AN-A0FY</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-B6-A0RN</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-AR-A1AJ</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                project synchronous_malignancy ajcc_pathologic_stage  \\\n",
       "submitter_id                                                           \n",
       "TCGA-A7-A0DC  TCGA-BRCA                     No              Stage IA   \n",
       "TCGA-D8-A1XG  TCGA-BRCA                     No            Stage IIIB   \n",
       "TCGA-AN-A0FY  TCGA-BRCA                     No              Stage IA   \n",
       "TCGA-B6-A0RN  TCGA-BRCA                     No              Stage IA   \n",
       "TCGA-AR-A1AJ  TCGA-BRCA                     No               Stage I   \n",
       "\n",
       "              days_to_diagnosis laterality  \n",
       "submitter_id                                \n",
       "TCGA-A7-A0DC                0.0        NaN  \n",
       "TCGA-D8-A1XG                0.0      Right  \n",
       "TCGA-AN-A0FY                0.0       Left  \n",
       "TCGA-B6-A0RN                0.0      Right  \n",
       "TCGA-AR-A1AJ                0.0      Right  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1098, 101)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pam50 = pd.read_csv(root /\"BRCA_PAM50_labels.csv\",index_col=0)\n",
    "clinical_biolinks = pd.read_csv(root /\"BRCA_clinical_data.csv\",index_col=1)\n",
    "\n",
    "display(pam50.iloc[:5,:5])\n",
    "display(pam50.shape)\n",
    "display(clinical_biolinks.iloc[:5,:5])\n",
    "display(clinical_biolinks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd066d50",
   "metadata": {},
   "source": [
    "## Data Processing Summary\n",
    "\n",
    "- **Transpose Data**: All raw data (miRNA, RNA, etc.) is flipped so rows represent patients and columns represent features.\n",
    "- **Standardize Patient IDs**: Patient IDs in all tables are cleaned to the 12-character TCGA format (e.g., `TCGA-AB-1234`) for matching.\n",
    "- **Handle Duplicates**: Duplicate patient rows are averaged in the omics data. The first entry is kept for duplicate patients in the clinical data.\n",
    "- **Impute Missing Values (KNN)**: Missing data (NaNs) in the omics datasets are estimated and filled using **K-Nearest Neighbors (KNN)** imputation.\n",
    "- **Find Common Patients**: The script identifies the largest common cohort of patients that exist in all datasets.\n",
    "- **Subset Data**: All data tables are filtered down to only this common list of patients, ensuring perfect alignment.\n",
    "- **Extract Target**: The **PAM50 subtype** column is pulled from the corresponding data table to be used as the final prediction target (y-variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128f63dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miRNA (samples, features): (1189, 503)\n",
      "RNA (samples, features): (1212, 18321)\n",
      "Methylation (samples, features): (885, 20107)\n",
      "Clinical (samples, features): (1097, 18)\n",
      "\n",
      "Methylation shape: (791, 20106)\n",
      "RNA shape: (1093, 18321)\n",
      "miRNA shape: (1079, 503)\n",
      "Clinical shape: (1097, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 23:39:27,784 - bioneuralnet.utils.data - INFO - Starting KNN imputation (k=5) on DataFrame (shape: (791, 20106)).\n",
      "2025-11-12 23:39:30,051 - bioneuralnet.utils.data - INFO - KNN imputation complete\n",
      "2025-11-12 23:39:30,423 - bioneuralnet.utils.data - INFO - Starting KNN imputation (k=5) on DataFrame (shape: (1093, 18321)).\n",
      "2025-11-12 23:39:51,503 - bioneuralnet.utils.data - INFO - KNN imputation complete\n",
      "2025-11-12 23:39:51,514 - bioneuralnet.utils.data - INFO - Starting KNN imputation (k=5) on DataFrame (shape: (1079, 503)).\n",
      "2025-11-12 23:39:52,287 - bioneuralnet.utils.data - INFO - KNN imputation complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found: 769 patients across all data types.\n",
      "\n",
      "Final shapes:\n",
      "meth: (769, 20106)\n",
      "rna: (769, 18321)\n",
      "mirna: (769, 503)\n",
      "pam50: (769, 1)\n",
      "clinical: (769, 119)\n",
      "targets: (769,)\n"
     ]
    }
   ],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "meth = meth_raw.T\n",
    "rna = rna_raw.T\n",
    "mirna = mirna_raw.T\n",
    "clinical_firehose = clinical_raw.T\n",
    "\n",
    "\n",
    "print(f\"miRNA (samples, features): {mirna.shape}\")\n",
    "print(f\"RNA (samples, features): {rna.shape}\")\n",
    "print(f\"Methylation (samples, features): {meth.shape}\")\n",
    "print(f\"Clinical (samples, features): {clinical_firehose.shape}\")\n",
    "\n",
    "def trim_barcode(idx):\n",
    "    return idx.to_series().str.slice(0, 12)\n",
    "\n",
    "# Standardize patient IDs across all files\n",
    "meth.index = trim_barcode(meth.index)\n",
    "rna.index = trim_barcode(rna.index)\n",
    "mirna.index = trim_barcode(mirna.index)\n",
    "clinical_firehose.index = clinical_firehose.index.str.upper()\n",
    "clinical_firehose.index.name = \"Patient_ID\"\n",
    "\n",
    "meth = meth.apply(pd.to_numeric, errors='coerce')\n",
    "meth = meth.drop(columns=[\"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "rna = rna.apply(pd.to_numeric, errors='coerce')\n",
    "mirna = mirna.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "meth = meth.groupby(meth.index).mean()\n",
    "rna = rna.groupby(rna.index).mean()\n",
    "mirna = mirna.groupby(mirna.index).mean()\n",
    "\n",
    "# For any duplicate rows in the clinical data, we keep the first occurrence\n",
    "clinical = clinical_firehose[~clinical_firehose.index.duplicated(keep='first')]\n",
    "\n",
    "for df in [meth, rna, mirna]:\n",
    "    df.columns = df.columns.str.replace(r\"\\?\", \"unknown_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"\\|\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(\"-\", \"_\", regex=False)\n",
    "    df.columns = df.columns.str.replace(r\"_+\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.strip(\"_\")\n",
    "\n",
    "print(f\"\\nMethylation shape: {meth.shape}\")\n",
    "print(f\"RNA shape: {rna.shape}\")\n",
    "print(f\"miRNA shape: {mirna.shape}\")\n",
    "print(f\"Clinical shape: {clinical.shape}\")\n",
    "\n",
    "# --- 4. KNN IMPUTATION (Outside Loop, as instructed) ---\n",
    "\n",
    "meth.columns = pd.Index(meth.columns.tolist())\n",
    "rna.columns = pd.Index(rna.columns.tolist())\n",
    "mirna.columns = pd.Index(mirna.columns.tolist())\n",
    "\n",
    "# --- 3. KNN IMPUTATION ---\n",
    "\n",
    "# Impute missing values using KNN on the finalized omics data\n",
    "# This step should now succeed as the column labels are strictly aligned with the underlying data array.\n",
    "meth = bnn.utils.data.impute_omics_knn(meth, n_neighbors=5) # This should now work\n",
    "rna = bnn.utils.data.impute_omics_knn(rna, n_neighbors=5)\n",
    "mirna = bnn.utils.data.impute_omics_knn(mirna, n_neighbors=5)\n",
    "\n",
    "# --- 4. Clinical Merge and Final Alignment ---\n",
    "\n",
    "# Handle duplicate patient IDs in clinical data (Keep first occurrence)\n",
    "clinical_biolinks = clinical_biolinks[~clinical_biolinks.index.duplicated(keep='first')]\n",
    "clinical_firehose = clinical_firehose[~clinical_firehose.index.duplicated(keep='first')]\n",
    "\n",
    "# Intersect patients common to both clinical sources and merge\n",
    "common_clinical_patients = clinical_biolinks.index.intersection(clinical_firehose.index)\n",
    "clinical_biolinks = clinical_biolinks.loc[common_clinical_patients]\n",
    "clinical_firehose = clinical_firehose.loc[common_clinical_patients]\n",
    "clinical = pd.concat([clinical_biolinks, clinical_firehose], axis=1)\n",
    "clinical.index.name = \"Patient_ID\"\n",
    "\n",
    "\n",
    "# Determine the final list of patients present in ALL datasets\n",
    "common_patients = sorted(\n",
    "    set(meth.index) & \n",
    "    set(rna.index) & \n",
    "    set(mirna.index) & \n",
    "    set(pam50.index) & \n",
    "    set(clinical.index)\n",
    ")\n",
    "\n",
    "print(f\"\\nFound: {len(common_patients)} patients across all data types.\")\n",
    "\n",
    "meth = meth.loc[common_patients]\n",
    "rna = rna.loc[common_patients]\n",
    "mirna = mirna.loc[common_patients]\n",
    "pam50 = pam50.loc[common_patients]\n",
    "clinical = clinical.loc[common_patients]\n",
    "\n",
    "\n",
    "targets = pam50['BRCA_Subtype_PAM50'] \n",
    "\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"meth: {meth.shape}\")\n",
    "print(f\"rna: {rna.shape}\")\n",
    "print(f\"mirna: {mirna.shape}\")\n",
    "print(f\"pam50: {pam50.shape}\")\n",
    "print(f\"clinical: {clinical.shape}\")\n",
    "print(f\"targets: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee114802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 23:39:52,362 - bioneuralnet.utils.data - INFO - Starting Beta-to-M value conversion (shape: (769, 20106)). Epsilon: 1e-06\n",
      "2025-11-12 23:39:53,549 - bioneuralnet.utils.data - INFO - Beta-to-M conversion complete.\n"
     ]
    }
   ],
   "source": [
    "# drop unwanted columns from clinical data\n",
    "clinical.drop(columns=[\"Composite Element REF\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "# we transform the methylation beta values to M-values and drop unwanted columns\n",
    "meth_m = meth.drop(columns=[\"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "# convert beta values to M-values using bioneuralnet utility with small epsilon to avoid log(0)\n",
    "meth_m = bnn.utils.beta_to_m(meth_m, eps=1e-6) \n",
    "\n",
    "# lastly we turn the target labels into numerical classes\n",
    "mapping_brca = {\n",
    "    'LumA': 0, \n",
    "    'Her2': 1, \n",
    "    'LumB': 2, \n",
    "    'Basal': 3, \n",
    "    'Normal': 4\n",
    "}\n",
    "target_labels = targets.map(mapping_brca).to_frame(name=\"target\")\n",
    "\n",
    "X_meth = meth_m.loc[targets.index]\n",
    "X_rna = rna.loc[targets.index]\n",
    "X_mirna = mirna.loc[targets.index]\n",
    "Y_labels = target_labels.loc[targets.index]\n",
    "clinical_processed = clinical.loc[targets.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f35bd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2BP1</th>\n",
       "      <th>A2LD1</th>\n",
       "      <th>A2M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>-0.094004</td>\n",
       "      <td>-1.251175</td>\n",
       "      <td>-2.113585</td>\n",
       "      <td>0.765262</td>\n",
       "      <td>0.345896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>0.812517</td>\n",
       "      <td>-0.237291</td>\n",
       "      <td>-1.658888</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.630221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>0.931878</td>\n",
       "      <td>-0.059301</td>\n",
       "      <td>-1.369104</td>\n",
       "      <td>1.628617</td>\n",
       "      <td>0.972130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A1BG      A1CF     A2BP1     A2LD1       A2M\n",
       "patient                                                       \n",
       "TCGA-3C-AAAU -0.094004 -1.251175 -2.113585  0.765262  0.345896\n",
       "TCGA-3C-AALI  0.812517 -0.237291 -1.658888  0.997440  0.630221\n",
       "TCGA-3C-AALJ  0.931878 -0.059301 -1.369104  1.628617  0.972130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(769, 20106)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unknown_100133144</th>\n",
       "      <th>unknown_100134869</th>\n",
       "      <th>unknown_10357</th>\n",
       "      <th>unknown_10431</th>\n",
       "      <th>unknown_155060</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>4.032489</td>\n",
       "      <td>3.692829</td>\n",
       "      <td>5.704604</td>\n",
       "      <td>8.672694</td>\n",
       "      <td>10.213110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>3.211931</td>\n",
       "      <td>4.119273</td>\n",
       "      <td>6.124231</td>\n",
       "      <td>9.139279</td>\n",
       "      <td>9.011343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>3.538886</td>\n",
       "      <td>3.206237</td>\n",
       "      <td>7.269570</td>\n",
       "      <td>10.410275</td>\n",
       "      <td>9.209506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              unknown_100133144  unknown_100134869  unknown_10357  \\\n",
       "patient                                                             \n",
       "TCGA-3C-AAAU           4.032489           3.692829       5.704604   \n",
       "TCGA-3C-AALI           3.211931           4.119273       6.124231   \n",
       "TCGA-3C-AALJ           3.538886           3.206237       7.269570   \n",
       "\n",
       "              unknown_10431  unknown_155060  \n",
       "patient                                      \n",
       "TCGA-3C-AAAU       8.672694       10.213110  \n",
       "TCGA-3C-AALI       9.139279        9.011343  \n",
       "TCGA-3C-AALJ      10.410275        9.209506  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(769, 18321)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa_let_7a_1</th>\n",
       "      <th>hsa_let_7a_2</th>\n",
       "      <th>hsa_let_7a_3</th>\n",
       "      <th>hsa_let_7b</th>\n",
       "      <th>hsa_let_7c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>13.129765</td>\n",
       "      <td>14.117933</td>\n",
       "      <td>13.147714</td>\n",
       "      <td>14.595135</td>\n",
       "      <td>8.414890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>12.918069</td>\n",
       "      <td>13.922300</td>\n",
       "      <td>12.913194</td>\n",
       "      <td>14.512657</td>\n",
       "      <td>9.646536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>13.012033</td>\n",
       "      <td>14.010002</td>\n",
       "      <td>13.028483</td>\n",
       "      <td>13.419612</td>\n",
       "      <td>9.312455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hsa_let_7a_1  hsa_let_7a_2  hsa_let_7a_3  hsa_let_7b  hsa_let_7c\n",
       "patient                                                                       \n",
       "TCGA-3C-AAAU     13.129765     14.117933     13.147714   14.595135    8.414890\n",
       "TCGA-3C-AALI     12.918069     13.922300     12.913194   14.512657    9.646536\n",
       "TCGA-3C-AALJ     13.012033     14.010002     13.028483   13.419612    9.312455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(769, 503)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>synchronous_malignancy</th>\n",
       "      <th>ajcc_pathologic_stage</th>\n",
       "      <th>days_to_diagnosis</th>\n",
       "      <th>laterality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>TCGA-BRCA</td>\n",
       "      <td>No</td>\n",
       "      <td>Stage IIB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                project synchronous_malignancy ajcc_pathologic_stage  \\\n",
       "patient                                                                \n",
       "TCGA-3C-AAAU  TCGA-BRCA                     No               Stage X   \n",
       "TCGA-3C-AALI  TCGA-BRCA                     No             Stage IIB   \n",
       "TCGA-3C-AALJ  TCGA-BRCA                     No             Stage IIB   \n",
       "\n",
       "              days_to_diagnosis laterality  \n",
       "patient                                     \n",
       "TCGA-3C-AAAU                0.0       Left  \n",
       "TCGA-3C-AALI                0.0      Right  \n",
       "TCGA-3C-AALJ                0.0      Right  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(769, 118)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         419\n",
       "2         140\n",
       "3         130\n",
       "1          46\n",
       "4          34\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_meth.iloc[:3,:5])\n",
    "display(X_meth.shape)\n",
    "\n",
    "display(X_rna.iloc[:3,:5])\n",
    "display(X_rna.shape)\n",
    "\n",
    "display(X_mirna.iloc[:3,:5])\n",
    "display(X_mirna.shape)\n",
    "\n",
    "display(clinical_processed.iloc[:3,:5])\n",
    "display(clinical_processed.shape)\n",
    "\n",
    "display(Y_labels.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09265512",
   "metadata": {},
   "source": [
    "Feature Selection Methodology for BRCA\n",
    "\n",
    "Supported Methods and Interpretation\n",
    "\n",
    "BioNeuralNet provides three techniques for feature selection, allowing for different views of the data's statistical profile:\n",
    "\n",
    "    Variance Thresholding: Identifies features with the highest overall variance across all samples.\n",
    "\n",
    "    ANOVA F-test: Pinpoints features that best distinguish between the target classes (LumA, LumB, Her2, Basal, and Normal).\n",
    "\n",
    "    Random Forest Importance: Assesses feature utility based on its contribution to a predictive non-linear model.\n",
    "\n",
    "BRCA Cohort Selection Strategy\n",
    "\n",
    "A dimensionality reduction step was essential for managing the high-feature-count omics data, given the complexity of the BRCA network:\n",
    "\n",
    "    High-Feature Datasets: Both DNA Methylation (20,106 features) and RNA (18,321 features) required significant feature reduction.\n",
    "\n",
    "    Filtering Process: The top 6,000 features were initially extracted from the Methylation and RNA datasets using all three methods.\n",
    "\n",
    "    Final Set: A consensus set was built by finding the intersection of features selected by the ANOVA F-test and Random Forest Importance, ensuring both statistical relevance and model-based utility.\n",
    "\n",
    "    Low-Feature Datasets: The miRNA data (503 features) was passed through without selection, as its feature count was already manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa70dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 23:39:56,760 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:39:56,761 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:39:56,761 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n",
      "2025-11-12 23:39:56,869 - bioneuralnet.utils.preprocess - INFO - Selected top 6000 features by variance\n",
      "2025-11-12 23:39:59,747 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:39:59,748 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:39:59,748 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n",
      "2025-11-12 23:39:59,842 - bioneuralnet.utils.preprocess - INFO - Selected top 6000 features by variance\n",
      "2025-11-12 23:40:03,008 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:40:03,009 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:40:03,009 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n",
      "2025-11-12 23:40:03,181 - bioneuralnet.utils.preprocess - INFO - Selected 6000 features by ANOVA (task=classification), 17514 significant, 0 padded\n",
      "2025-11-12 23:40:06,137 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:40:06,138 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:40:06,138 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n",
      "2025-11-12 23:40:06,289 - bioneuralnet.utils.preprocess - INFO - Selected 6000 features by ANOVA (task=classification), 17214 significant, 0 padded\n",
      "2025-11-12 23:40:09,533 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:40:09,533 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:40:09,533 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n",
      "2025-11-12 23:40:18,075 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-12 23:40:18,076 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 0 NaNs after median imputation\n",
      "2025-11-12 23:40:18,076 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 0 columns dropped due to zero variance\n"
     ]
    }
   ],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "# feature selection\n",
    "meth_highvar = bnn.utils.select_top_k_variance(X_meth, k=6000)\n",
    "rna_highvar = bnn.utils.select_top_k_variance(X_rna, k=6000)\n",
    "\n",
    "meth_af = bnn.utils.top_anova_f_features(X_meth, Y_labels, max_features=6000)\n",
    "rna_af = bnn.utils.top_anova_f_features(X_rna, Y_labels, max_features=6000)\n",
    "\n",
    "meth_rf = bnn.utils.select_top_randomforest(X_meth, Y_labels, top_k=6000)\n",
    "rna_rf = bnn.utils.select_top_randomforest(X_rna, Y_labels, top_k=6000)\n",
    "\n",
    "meth_var_set = set(meth_highvar.columns)\n",
    "meth_anova_set = set(meth_af.columns)\n",
    "meth_rf_set = set(meth_rf.columns)\n",
    "\n",
    "rna_var_set = set(rna_highvar.columns)\n",
    "rna_anova_set = set(rna_af.columns)\n",
    "rna_rf_set = set(rna_rf.columns)\n",
    "\n",
    "meth_inter1 = list(meth_anova_set & meth_var_set)\n",
    "meth_inter2 = list(meth_rf_set & meth_var_set)\n",
    "meth_inter3 = list(meth_anova_set & meth_rf_set)\n",
    "meth_all_three = list(meth_anova_set & meth_var_set & meth_rf_set)\n",
    "\n",
    "rna_inter4 = list(rna_anova_set & rna_var_set)\n",
    "rna_inter5 = list(rna_rf_set & rna_var_set)\n",
    "rna_inter6 = list(rna_anova_set & rna_rf_set)\n",
    "rna_all_three = list(rna_anova_set & rna_var_set & rna_rf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc981cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM THE 6000 Methylation feature selection:\n",
      "\n",
      "Anova-F & variance selection share: 2092 features\n",
      "Random Forest & variance selection share: 1870 features\n",
      "Anova-F & Random Forest share: 2203 features\n",
      "All three methods agree on: 814 features\n"
     ]
    }
   ],
   "source": [
    "print(\"FROM THE 6000 Methylation feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(meth_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(meth_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(meth_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(meth_all_three)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da639dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM THE 6000 RNA feature selection:\n",
      "\n",
      "Anova-F & variance selection share: 2359 features\n",
      "Random Forest & variance selection share: 2191 features\n",
      "Anova-F & Random Forest share: 2500 features\n",
      "All three methods agree on: 1124 features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFROM THE 6000 RNA feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(rna_inter4)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(rna_inter5)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(rna_inter6)} features\")\n",
    "print(f\"All three methods agree on: {len(rna_all_three)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6d4a4",
   "metadata": {},
   "source": [
    "## Feature Selection Summary: ANOVA-RF Intersection\n",
    "\n",
    "The final set of features was determined by the **intersection** of those highlighted by the **ANOVA F-test** and **Random Forest Importance**. This methodology provides a balanced filter, capturing features with both high class-separability (ANOVA) and significant predictive value in a non-linear model (Random Forest). The resulting feature pool is considered highly relevant for the subsequent modeling tasks.\n",
    "\n",
    "### Feature Overlap Results\n",
    "\n",
    "The table below quantifies the shared features identified by the different selection techniques for each omics type.\n",
    "\n",
    "| Omics Data Type | ANOVA-F & Variance | RF & Variance | ANOVA-F & Random Forest (Selected) | All Three Agree |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Methylation** | 2,092 features | 1,870 features | **2,203 features** | 814 features |\n",
    "| **RNA** | 2,359 features | 2,191 features | **2,500 features** | 1,124 features |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc89f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Shapes for Modeling\n",
      "Methylation (X1): (769, 2203)\n",
      "RNA-Seq (X2): (769, 2500)\n",
      "miRNA-Seq (X3): (769, 503)\n",
      "Labels (Y): (769, 1)\n"
     ]
    }
   ],
   "source": [
    "X_meth_selected = X_meth[meth_inter3]\n",
    "X_rna_selected = X_rna[rna_inter6]\n",
    "\n",
    "print(\"\\nFinal Shapes for Modeling\")\n",
    "print(f\"Methylation (X1): {X_meth_selected.shape}\")\n",
    "print(f\"RNA-Seq (X2): {X_rna_selected.shape}\")\n",
    "print(f\"miRNA-Seq (X3): {X_mirna.shape}\")\n",
    "print(f\"Labels (Y): {Y_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2168980",
   "metadata": {},
   "source": [
    "## Data Availability\n",
    "\n",
    "To facilitate rapid experimentation and reproduction of our results, the fully processed and feature-selected dataset used in this analysis has been made available directly within the package.\n",
    "\n",
    "Users can load this dataset, bypassing all preceding data acquisition, preprocessing, and feature selection steps. This allows users to proceed immediately from this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0486d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"/home/vicente/Github/BioNeuralNet/bioneuralnet/datasets/brca\")\n",
    "X_meth_selected.to_csv(out_dir / \"meth.csv\", index=True)\n",
    "X_rna_selected.to_csv(out_dir / \"rna.csv\", index=True)\n",
    "X_mirna.to_csv(out_dir / \"mirna.csv\", index=True)\n",
    "\n",
    "clinical_processed.to_csv(out_dir / \"clinical.csv\", index=True)\n",
    "Y_labels.to_csv(out_dir / \"target.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d0340f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mirna': (769, 503),\n",
       " 'target': (769, 1),\n",
       " 'clinical': (769, 118),\n",
       " 'rna': (769, 2500),\n",
       " 'meth': (769, 2203)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "tgca_brca = bnn.datasets.DatasetLoader(\"brca\")\n",
    "display(tgca_brca.shape)\n",
    "\n",
    "dna_meth = tgca_brca.data[\"meth\"]\n",
    "rna = tgca_brca.data[\"rna\"]\n",
    "mirna = tgca_brca.data[\"mirna\"]\n",
    "clinical = tgca_brca.data[\"clinical\"]\n",
    "target = tgca_brca.data[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45f316d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples dropped by dropna: 49\n",
      "Final shape of clinical data: (769, 69)\n"
     ]
    }
   ],
   "source": [
    "samples_before = clinical.shape[1]\n",
    "\n",
    "clinical_half_len = clinical.shape[1] /2\n",
    "clinical.dropna(inplace=True, axis=1, thresh=clinical_half_len)\n",
    "samples_after = clinical.shape[1]\n",
    "print(f\"Samples dropped by dropna: {samples_before - samples_after}\")\n",
    "print(f\"Final shape of clinical data: {clinical.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "338dc995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 00:41:28,700 - bioneuralnet.utils.preprocess - INFO - [Inf]: Replaced 0 infinite values\n",
      "2025-11-13 00:41:28,700 - bioneuralnet.utils.preprocess - INFO - [NaN]: Replaced 15 NaNs after median imputation\n",
      "2025-11-13 00:41:28,701 - bioneuralnet.utils.preprocess - INFO - [Zero-Var]: 1 columns dropped due to zero variance\n",
      "2025-11-13 00:41:29,026 - bioneuralnet.utils.preprocess - INFO - Selected top 7 features by RandomForest importance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>year_of_diagnosis</th>\n",
       "      <th>laterality_Right</th>\n",
       "      <th>country_of_residence_at_enrollment_United States</th>\n",
       "      <th>race_black or african american</th>\n",
       "      <th>method_of_diagnosis_Core Biopsy</th>\n",
       "      <th>metastasis_at_diagnosis_Missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>20211.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>18538.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALJ</th>\n",
       "      <td>22848.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age_at_diagnosis  year_of_diagnosis  laterality_Right  \\\n",
       "patient                                                               \n",
       "TCGA-3C-AAAU           20211.0             2004.0             False   \n",
       "TCGA-3C-AALI           18538.0             2003.0              True   \n",
       "TCGA-3C-AALJ           22848.0             2011.0              True   \n",
       "\n",
       "              country_of_residence_at_enrollment_United States  \\\n",
       "patient                                                          \n",
       "TCGA-3C-AAAU                                              True   \n",
       "TCGA-3C-AALI                                              True   \n",
       "TCGA-3C-AALJ                                              True   \n",
       "\n",
       "              race_black or african american  method_of_diagnosis_Core Biopsy  \\\n",
       "patient                                                                         \n",
       "TCGA-3C-AAAU                           False                            False   \n",
       "TCGA-3C-AALI                            True                             True   \n",
       "TCGA-3C-AALJ                            True                             True   \n",
       "\n",
       "              metastasis_at_diagnosis_Missing  \n",
       "patient                                        \n",
       "TCGA-3C-AAAU                             True  \n",
       "TCGA-3C-AALI                             True  \n",
       "TCGA-3C-AALJ                             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "# for more details on the preprocessing functions, see `bioneuralnet.utils.preprocess`\n",
    "clinical_preprocessed = bnn.utils.preprocess_clinical(\n",
    "    clinical, \n",
    "    target, \n",
    "    top_k=7, \n",
    "    scale=False,\n",
    "    ignore_columns = [\n",
    "    'days_to_birth',\n",
    "    'years_to_birth',\n",
    "    'age_at_index',\n",
    "    'updated_datetime',\n",
    "    'bcr_patient_barcode',\n",
    "    'diagnosis_id',\n",
    "    'icd_10_code',\n",
    "    'ajcc_staging_system_edition',\n",
    "    'date_of_initial_pathologic_diagnosis',\n",
    "    'gender.1', \n",
    "    'race.1', \n",
    "    'ethnicity.1',\n",
    "    'number_of_lymph_nodes',\n",
    "    'vital_status',\n",
    "    'vital_status.1',\n",
    "    'days_to_death',\n",
    "    'days_to_death.1',\n",
    "    'days_to_last_followup',\n",
    "    'treatments_radiation_days_to_treatment_end',\n",
    "    'treatments_radiation_days_to_treatment_start',\n",
    "    'ajcc_pathologic_stage',\n",
    "    'pathologic_stage',\n",
    "    \"ajcc_pathologic_t\",\n",
    "    'pathology_T_stage',\n",
    "    'pathology_N_stage',\n",
    "    'pathology_M_stage',]\n",
    ")\n",
    "\n",
    "#print(clinical_preprocessed.columns)\n",
    "display(clinical_preprocessed.iloc[:3,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb8500",
   "metadata": {},
   "source": [
    "## Building a Multi-Omics Network\n",
    "\n",
    "We built a k-NN cosine similarity graph to capture relationships across omics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4646135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in X_train_full: 0\n",
      "Nan value in X_train_full after dropping: 0\n",
      "X_train_full shape: (769, 5206)\n",
      "\n",
      "Network shape: (5206, 5206)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train_full = pd.concat([dna_meth, rna, mirna], axis=1)\n",
    "\n",
    "print(f\"Nan values in X_train_full: {X_train_full.isna().sum().sum()}\")\n",
    "X_train_full = X_train_full.dropna()\n",
    "print(f\"Nan value in X_train_full after dropping: {X_train_full.isna().sum().sum()}\")\n",
    "\n",
    "print(f\"X_train_full shape: {X_train_full.shape}\")\n",
    "# building the graph using the similarity graph function with k=15\n",
    "A_train = bnn.utils.gen_similarity_graph(X_train_full, k=15)\n",
    "\n",
    "print(f\"\\nNetwork shape: {A_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d776c",
   "metadata": {},
   "source": [
    "## Reproducibility and Seeding\n",
    "\n",
    "To ensure our experimental results are fully reproducible, a single global seed is set at the beginning of the analysis.\n",
    "\n",
    "This utility function propagates the seed to all sources of randomness, including `random`, `numpy`, and `torch` (for both CPU and GPU). Critically, it also configures the PyTorch cuDNN backend to use deterministic algorithms.\n",
    "\n",
    "**for each DPMON outer iteration, the seed is incremented to generate a different internal test/train split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c052f712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 00:41:54,623 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1804\n",
      "2025-11-13 00:41:54,625 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:41:54,625 - bioneuralnet.utils.data - INFO - Seed setting complete\n"
     ]
    }
   ],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "SEED = 1804\n",
    "bnn.utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f8a5b",
   "metadata": {},
   "source": [
    "## Classification using DPMON: Training and Evaluation\n",
    "\n",
    "\n",
    "### SAGE Analysis of Hyperparameter Optimization\n",
    "\n",
    "| Seed | Internal Avg Acc | Internal Std Dev | gnn_layer_num | gnn_hidden_dim | lr | weight_decay | nn_hidden_dim1 | nn_hidden_dim2 | num_epochs |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **1804** | 0.8062 | 0.2817 | 64 | 8 | 0.004644 | 0.001269 | 64 | 128 | 512 |\n",
    "| **1805** | 0.8266 | 0.3003 | 16 | 8 | 0.000322 | 0.018485 | 128 | 128 | 1024 |\n",
    "| **1806** | 0.7629 | 0.3341 | 16 | 64 | 0.000316 | 0.065466 | 64 | 32 | 4096 |\n",
    "| **1807** | 0.9046 | 0.0470 | 4 | 32 | 0.004406 | 0.017536 | 32 | 64 | 8192 |\n",
    "| **1808** | 0.9905 | 0.0059 | 8 | 32 | 0.005560 | 0.000111 | 32 | 64 | 2048 |\n",
    "\n",
    "### SAGE Final Results\n",
    "\n",
    "| | Mean | Std Dev |\n",
    "|:---|---:|---:|\n",
    "| **Accuracy** | **0.9774** | **0.0190** |\n",
    "| **F1 Weighted** | **0.9684** | **0.0286** |\n",
    "| **F1 Macro** | **0.8957** | **0.1017** |\n",
    "\n",
    "\n",
    "### GCN Analysis of Hyperparameter Optimization\n",
    "\n",
    "| Seed | Internal Avg Acc | Internal Std Dev | gnn_layer_num | gnn_hidden_dim | lr | weight_decay | nn_hidden_dim1 | nn_hidden_dim2 | num_epochs |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **1804** | 1.0000 | 0.0000 | 64 | 16 | 0.000302 | 0.000130 | 64 | 16 | 2048 |\n",
    "| **1805** | 0.6680 | 0.0686 | 128 | 64 | 0.055114 | 0.002403 | 16 | 4 | 64 |\n",
    "| **1806** | 1.0000 | 0.0000 | 4 | 128 | 0.000714 | 0.012667 | 64 | 128 | 8192 |\n",
    "| **1807** | 0.6606 | 0.1201 | 8 | 64 | 0.020924 | 0.009291 | 16 | 128 | 256 |\n",
    "| **1808** | 0.9991 | 0.0008 | 8 | 32 | 0.005560 | 0.000111 | 32 | 64 | 2048 |\n",
    "\n",
    "### GCN Final Results\n",
    "\n",
    "| | Mean | Std Dev |\n",
    "|:---|---:|---:|\n",
    "| **Accuracy** | **0.9009** | **0.1238** |\n",
    "| **F1 Weighted** | **0.8697** | **0.1673** |\n",
    "| **F1 Macro** | **0.7880** | **0.2738** |\n",
    "\n",
    "\n",
    "### GAT Analysis of Hyperparameter Optimization\n",
    "\n",
    "| Seed | Internal Avg Acc | Internal Std Dev | gnn_layer_num | gnn_hidden_dim | lr | weight_decay | nn_hidden_dim1 | nn_hidden_dim2 | num_epochs |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **1804** | 0.7195 | 0.0251 | 8 | 64 | 0.042316 | 0.025413 | 64 | 16 | 64 |\n",
    "| **1805** | 0.9991 | 0.0015 | 16 | 8 | 0.000322 | 0.018485 | 128 | 128 | 1024 |\n",
    "| **1806** | 0.7009 | 0.3219 | 4 | 128 | 0.000714 | 0.012667 | 64 | 128 | 8192 |\n",
    "| **1807** | 0.5388 | 0.1508 | 8 | 64 | 0.020924 | 0.009291 | 16 | 128 | 256 |\n",
    "| **1808** | 0.7560 | 0.0529 | 128 | 4 | 0.003024 | 0.078813 | 8 | 128 | 8192 |\n",
    "\n",
    "### GAT Final Results\n",
    "\n",
    "| | Mean | Std Dev |\n",
    "|:---|:---|:---|\n",
    "| **Accuracy** | **0.8398** | **0.1419** |\n",
    "| **F1 Weighted** | **0.8008** | **0.1781** |\n",
    "| **F1 Macro** | **0.6495** | **0.2936** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a2f5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 00:41:54,650 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1804\n",
      "2025-11-13 00:41:54,651 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:41:54,652 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:41:54,653 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\n",
      "2025-11-13 00:41:54,653 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:41:54,653 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:41:54,711 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:41:54,711 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:41:54,929 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:41:58,530 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:41:58,531\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:42:44,616\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0035s.\n",
      "2025-11-13 00:42:44,645 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 64, 'gnn_hidden_dim': 8, 'lr': 0.004644255822868241, 'weight_decay': 0.001269416591195491, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 512}\n",
      "2025-11-13 00:42:44,646 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9258398413658142\n",
      "2025-11-13 00:42:44,646 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.988296488946684\n",
      "2025-11-13 00:42:44,648 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0             64               8  0.004644      0.001269              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128         512  \n",
      "2025-11-13 00:42:44,650 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 64, 'gnn_hidden_dim': 8, 'lr': 0.004644255822868241, 'weight_decay': 0.001269416591195491, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 512}\n",
      "2025-11-13 00:42:44,650 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 64, 'gnn_hidden_dim': 8, 'lr': 0.004644255822868241, 'weight_decay': 0.001269416591195491, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 512}\n",
      "2025-11-13 00:42:44,650 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:42:44,650 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:42:44,884 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:42:48,703 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:42:49,828 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9792\n",
      "2025-11-13 00:42:49,831 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:42:49,833 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:42:51,017 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9584\n",
      "2025-11-13 00:42:51,020 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:42:51,021 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:42:52,131 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.4811\n",
      "2025-11-13 00:42:52,134 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:42:52,135 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.9792\n",
      "2025-11-13 00:42:52,135 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.8062\n",
      "2025-11-13 00:42:52,136 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.2817\n",
      "2025-11-13 00:42:52,136 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:42:52,139 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1805\n",
      "2025-11-13 00:42:52,139 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:42:52,140 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:42:52,140 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\n",
      "2025-11-13 00:42:52,140 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:42:52,140 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:42:52,167 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:42:52,168 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:42:52,387 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:42:56,041 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:42:56,041\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:43:39,593\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0122s.\n",
      "2025-11-13 00:43:39,618 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 00:43:39,618 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9288285374641418\n",
      "2025-11-13 00:43:39,619 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 1.0\n",
      "2025-11-13 00:43:39,622 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0             16               8  0.000322      0.018485             128   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128        1024  \n",
      "2025-11-13 00:43:39,624 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 00:43:39,625 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 00:43:39,625 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:43:39,625 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:43:39,847 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:43:43,508 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:43:45,759 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.4798\n",
      "2025-11-13 00:43:45,772 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:43:45,777 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:43:47,924 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:43:47,929 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:43:47,930 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:43:50,194 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:43:50,198 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:43:50,200 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 00:43:50,201 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.8266\n",
      "2025-11-13 00:43:50,201 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.3003\n",
      "2025-11-13 00:43:50,201 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:43:50,205 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1806\n",
      "2025-11-13 00:43:50,205 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:43:50,206 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:43:50,206 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\n",
      "2025-11-13 00:43:50,206 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:43:50,207 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:43:50,226 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:43:50,226 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:43:50,640 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:43:54,297 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:43:54,298\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:44:42,706\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0047s.\n",
      "2025-11-13 00:44:42,742 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 16, 'gnn_hidden_dim': 64, 'lr': 0.00031562940178489387, 'weight_decay': 0.0654656716940775, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 32, 'num_epochs': 4096}\n",
      "2025-11-13 00:44:42,743 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 1.0901015996932983\n",
      "2025-11-13 00:44:42,743 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 1.0\n",
      "2025-11-13 00:44:42,748 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0             16              64  0.000316      0.065466              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              32        4096  \n",
      "2025-11-13 00:44:42,752 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 64, 'lr': 0.00031562940178489387, 'weight_decay': 0.0654656716940775, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 32, 'num_epochs': 4096}\n",
      "2025-11-13 00:44:42,752 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 64, 'lr': 0.00031562940178489387, 'weight_decay': 0.0654656716940775, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 32, 'num_epochs': 4096}\n",
      "2025-11-13 00:44:42,753 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:44:42,753 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:44:42,989 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:44:46,713 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:45:00,971 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.3771\n",
      "2025-11-13 00:45:00,977 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:45:00,979 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:45:15,061 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9558\n",
      "2025-11-13 00:45:15,064 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:45:15,066 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:45:29,492 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9558\n",
      "2025-11-13 00:45:29,504 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:45:29,507 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.9558\n",
      "2025-11-13 00:45:29,507 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.7629\n",
      "2025-11-13 00:45:29,507 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.3341\n",
      "2025-11-13 00:45:29,508 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:45:29,512 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1807\n",
      "2025-11-13 00:45:29,512 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:45:29,513 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:45:29,513 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\n",
      "2025-11-13 00:45:29,513 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:45:29,513 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:45:29,534 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:45:29,535 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:45:29,823 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:45:33,759 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:45:33,760\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:46:15,739\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0079s.\n",
      "2025-11-13 00:46:15,773 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 4, 'gnn_hidden_dim': 32, 'lr': 0.004405958952433761, 'weight_decay': 0.017535626764004726, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 8192}\n",
      "2025-11-13 00:46:15,773 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9423158764839172\n",
      "2025-11-13 00:46:15,774 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9986996098829649\n",
      "2025-11-13 00:46:15,780 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              4              32  0.004406      0.017536              32   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              64        8192  \n",
      "2025-11-13 00:46:15,784 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 32, 'lr': 0.004405958952433761, 'weight_decay': 0.017535626764004726, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 8192}\n",
      "2025-11-13 00:46:15,785 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 32, 'lr': 0.004405958952433761, 'weight_decay': 0.017535626764004726, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 8192}\n",
      "2025-11-13 00:46:15,785 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:46:15,786 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:46:16,025 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:46:19,860 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:46:40,593 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9558\n",
      "2025-11-13 00:46:40,595 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:46:40,597 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:47:00,932 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.8947\n",
      "2025-11-13 00:47:00,935 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:47:00,936 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:47:20,074 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.8635\n",
      "2025-11-13 00:47:20,076 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:47:20,078 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.9558\n",
      "2025-11-13 00:47:20,078 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.9046\n",
      "2025-11-13 00:47:20,078 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0470\n",
      "2025-11-13 00:47:20,078 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:47:20,080 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1808\n",
      "2025-11-13 00:47:20,081 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:47:20,081 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:47:20,081 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\n",
      "2025-11-13 00:47:20,081 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:47:20,082 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:47:20,098 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:47:20,099 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:47:20,307 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:47:24,040 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:47:24,041\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:48:04,599\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0036s.\n",
      "2025-11-13 00:48:04,622 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:48:04,622 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9067111611366272\n",
      "2025-11-13 00:48:04,622 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9986996098829649\n",
      "2025-11-13 00:48:04,626 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim       lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              8              32  0.00556      0.000111              32   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              64        2048  \n",
      "2025-11-13 00:48:04,627 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:48:04,628 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:48:04,628 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:48:04,628 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:48:04,846 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:48:08,361 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:48:13,150 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9844\n",
      "2025-11-13 00:48:13,153 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:48:13,155 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:48:17,667 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9909\n",
      "2025-11-13 00:48:17,670 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:48:17,672 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:48:22,294 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9961\n",
      "2025-11-13 00:48:22,297 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:48:22,298 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.9961\n",
      "2025-11-13 00:48:22,299 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.9905\n",
      "2025-11-13 00:48:22,299 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0059\n",
      "2025-11-13 00:48:22,299 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9774 +/- 0.0190\n",
      "F1 Weighted: 0.9684 +/- 0.0286\n",
      "F1 Macro: 0.8957 +/- 0.1017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "output_dir_base_sage =  Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\")\n",
    "target = target.rename(columns={\"target\": \"phenotype\"})\n",
    "\n",
    "n_repeats = 5\n",
    "all_preds = []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    bnn.utils.set_seed(SEED+r)\n",
    "    dpmon_repeat = DPMON(\n",
    "        adjacency_matrix=A_train,\n",
    "        omics_list=[dna_meth, rna, mirna],\n",
    "        phenotype_data=target,\n",
    "        clinical_data=clinical_preprocessed,\n",
    "        repeat_num=3,\n",
    "        model='SAGE',\n",
    "        tune=True,\n",
    "        gpu=True,\n",
    "        cuda=0,\n",
    "        output_dir=output_dir_base_sage,\n",
    "    )\n",
    "    \n",
    "    predictions_df, _ = dpmon_repeat.run()\n",
    "    all_preds.append(predictions_df[\"Predicted\"].values)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "f1_macro_list = [f1_score(target, pred, average='macro') for pred in all_preds]\n",
    "f1_weighted_list = [f1_score(target, pred, average='weighted') for pred in all_preds]\n",
    "accuracy_list = [accuracy_score(target, pred) for pred in all_preds]\n",
    "\n",
    "avg_f1_macro = np.mean(f1_macro_list)\n",
    "std_f1_macro = np.std(f1_macro_list)\n",
    "\n",
    "avg_f1_weighted = np.mean(f1_weighted_list)\n",
    "std_f1_weighted = np.std(f1_weighted_list)\n",
    "\n",
    "avg_acc = np.mean(accuracy_list)\n",
    "std_acc = np.std(accuracy_list)\n",
    "\n",
    "print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "print(f\"F1 Weighted: {avg_f1_weighted:.4f} +/- {std_f1_weighted:.4f}\")\n",
    "print(f\"F1 Macro: {avg_f1_macro:.4f} +/- {std_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43396d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 00:48:22,330 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1804\n",
      "2025-11-13 00:48:22,331 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:48:22,331 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:48:22,331 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\n",
      "2025-11-13 00:48:22,332 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:48:22,332 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:48:22,350 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:48:22,350 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:48:22,561 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:48:26,095 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:48:26,095\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:49:06,673\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0041s.\n",
      "2025-11-13 00:49:06,697 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 64, 'gnn_hidden_dim': 16, 'lr': 0.000301535963829834, 'weight_decay': 0.000129636888188551, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 2048}\n",
      "2025-11-13 00:49:06,697 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 1.3331656455993652\n",
      "2025-11-13 00:49:06,697 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.8309492847854356\n",
      "2025-11-13 00:49:06,700 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0             64              16  0.000302       0.00013              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              16        2048  \n",
      "2025-11-13 00:49:06,702 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 64, 'gnn_hidden_dim': 16, 'lr': 0.000301535963829834, 'weight_decay': 0.000129636888188551, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 2048}\n",
      "2025-11-13 00:49:06,702 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 64, 'gnn_hidden_dim': 16, 'lr': 0.000301535963829834, 'weight_decay': 0.000129636888188551, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 2048}\n",
      "2025-11-13 00:49:06,702 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:49:06,702 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:49:06,952 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:49:10,714 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:49:16,053 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:49:16,055 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:49:16,057 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:49:21,376 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:49:21,379 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:49:21,380 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:49:26,765 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:49:26,767 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:49:26,769 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 00:49:26,770 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 1.0000\n",
      "2025-11-13 00:49:26,770 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0000\n",
      "2025-11-13 00:49:26,770 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:49:26,773 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1805\n",
      "2025-11-13 00:49:26,773 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:49:26,774 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:49:26,774 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\n",
      "2025-11-13 00:49:26,774 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:49:26,774 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:49:26,791 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:49:26,792 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:49:27,008 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:49:30,502 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:49:30,503\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:50:23,455\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0039s.\n",
      "2025-11-13 00:50:23,478 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 128, 'gnn_hidden_dim': 64, 'lr': 0.055114418414744085, 'weight_decay': 0.0024031949821038405, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 4, 'num_epochs': 64}\n",
      "2025-11-13 00:50:23,478 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 1.3409614562988281\n",
      "2025-11-13 00:50:23,478 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.7139141742522757\n",
      "2025-11-13 00:50:23,482 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0            128              64  0.055114      0.002403              16   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0               4          64  \n",
      "2025-11-13 00:50:23,483 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 128, 'gnn_hidden_dim': 64, 'lr': 0.055114418414744085, 'weight_decay': 0.0024031949821038405, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 4, 'num_epochs': 64}\n",
      "2025-11-13 00:50:23,483 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 128, 'gnn_hidden_dim': 64, 'lr': 0.055114418414744085, 'weight_decay': 0.0024031949821038405, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 4, 'num_epochs': 64}\n",
      "2025-11-13 00:50:23,484 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:50:23,484 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:50:23,696 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:50:27,497 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:50:27,977 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.5891\n",
      "2025-11-13 00:50:27,979 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:50:27,983 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:50:28,455 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7139\n",
      "2025-11-13 00:50:28,457 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:50:28,461 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:50:28,927 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7009\n",
      "2025-11-13 00:50:28,929 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:50:28,933 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.7139\n",
      "2025-11-13 00:50:28,933 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.6680\n",
      "2025-11-13 00:50:28,933 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0686\n",
      "2025-11-13 00:50:28,933 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:50:28,938 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1806\n",
      "2025-11-13 00:50:28,939 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:50:28,939 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:50:28,939 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\n",
      "2025-11-13 00:50:28,939 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:50:28,940 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:50:28,960 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:50:28,960 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:50:29,173 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:50:32,722 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:50:32,723\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:51:17,609\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0029s.\n",
      "2025-11-13 00:51:17,631 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 00:51:17,631 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9173226952552795\n",
      "2025-11-13 00:51:17,632 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 1.0\n",
      "2025-11-13 00:51:17,635 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              4             128  0.000714      0.012667              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128        8192  \n",
      "2025-11-13 00:51:17,637 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 00:51:17,637 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 00:51:17,637 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:51:17,637 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:51:17,854 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:51:21,397 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:53:10,415 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:53:10,418 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:53:10,425 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:55:00,139 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:55:00,142 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:55:00,149 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:56:50,144 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:56:50,148 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:56:50,155 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 00:56:50,155 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 1.0000\n",
      "2025-11-13 00:56:50,155 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0000\n",
      "2025-11-13 00:56:50,156 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:56:50,159 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1807\n",
      "2025-11-13 00:56:50,160 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:56:50,160 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:56:50,160 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\n",
      "2025-11-13 00:56:50,160 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:56:50,160 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:56:50,177 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:56:50,178 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:56:50,395 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:56:54,321 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:56:54,321\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:57:37,720\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0026s.\n",
      "2025-11-13 00:57:37,745 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 00:57:37,745 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9653679728507996\n",
      "2025-11-13 00:57:37,745 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9557867360208062\n",
      "2025-11-13 00:57:37,749 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              8              64  0.020924      0.009291              16   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128         256  \n",
      "2025-11-13 00:57:37,751 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 00:57:37,751 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 00:57:37,752 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:57:37,752 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:57:38,005 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:57:41,696 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:57:43,557 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7906\n",
      "2025-11-13 00:57:43,560 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:57:43,564 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:57:45,404 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.5540\n",
      "2025-11-13 00:57:45,406 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:57:45,411 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:57:47,286 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.6372\n",
      "2025-11-13 00:57:47,288 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:57:47,292 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.7906\n",
      "2025-11-13 00:57:47,293 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.6606\n",
      "2025-11-13 00:57:47,293 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.1201\n",
      "2025-11-13 00:57:47,293 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 00:57:47,296 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1808\n",
      "2025-11-13 00:57:47,297 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:57:47,297 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:57:47,297 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\n",
      "2025-11-13 00:57:47,297 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:57:47,298 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:57:47,316 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:57:47,317 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:57:47,534 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:57:51,449 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:57:51,450\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:58:39,664\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0036s.\n",
      "2025-11-13 00:58:39,695 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:58:39,695 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9069824814796448\n",
      "2025-11-13 00:58:39,695 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9986996098829649\n",
      "2025-11-13 00:58:39,700 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim       lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              8              32  0.00556      0.000111              32   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              64        2048  \n",
      "2025-11-13 00:58:39,702 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:58:39,702 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 32, 'lr': 0.005559565468877766, 'weight_decay': 0.00011124585182709967, 'nn_hidden_dim1': 32, 'nn_hidden_dim2': 64, 'num_epochs': 2048}\n",
      "2025-11-13 00:58:39,702 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:58:39,703 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:58:39,948 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:58:43,838 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 00:58:51,696 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9987\n",
      "2025-11-13 00:58:51,699 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 00:58:51,701 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 00:58:59,317 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9987\n",
      "2025-11-13 00:58:59,320 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 00:58:59,322 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 00:59:06,883 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 00:59:06,885 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 00:59:06,888 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 00:59:06,888 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.9991\n",
      "2025-11-13 00:59:06,888 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0008\n",
      "2025-11-13 00:59:06,888 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9009 +/- 0.1238\n",
      "F1 Weighted: 0.8697 +/- 0.1673\n",
      "F1 Macro: 0.7880 +/- 0.2738\n"
     ]
    }
   ],
   "source": [
    "output_dir_base_gcn = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\")\n",
    "\n",
    "n_repeats = 5\n",
    "all_preds = []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    bnn.utils.set_seed(SEED+r)\n",
    "    dpmon_repeat = DPMON(\n",
    "        adjacency_matrix=A_train,\n",
    "        omics_list=[dna_meth, rna, mirna],\n",
    "        phenotype_data=target,\n",
    "        clinical_data=clinical_preprocessed,\n",
    "        repeat_num=3,\n",
    "        model='GCN',\n",
    "        tune=True,\n",
    "        gpu=True,\n",
    "        cuda=0,\n",
    "        output_dir=output_dir_base_gcn,\n",
    "    )\n",
    "    \n",
    "    predictions_df, _ = dpmon_repeat.run()\n",
    "    all_preds.append(predictions_df[\"Predicted\"].values)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "f1_macro_list = [f1_score(target, pred, average='macro') for pred in all_preds]\n",
    "f1_weighted_list = [f1_score(target, pred, average='weighted') for pred in all_preds]\n",
    "accuracy_list = [accuracy_score(target, pred) for pred in all_preds]\n",
    "\n",
    "avg_f1_macro = np.mean(f1_macro_list)\n",
    "std_f1_macro = np.std(f1_macro_list)\n",
    "\n",
    "avg_f1_weighted = np.mean(f1_weighted_list)\n",
    "std_f1_weighted = np.std(f1_weighted_list)\n",
    "\n",
    "avg_acc = np.mean(accuracy_list)\n",
    "std_acc = np.std(accuracy_list)\n",
    "\n",
    "print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "print(f\"F1 Weighted: {avg_f1_weighted:.4f} +/- {std_f1_weighted:.4f}\")\n",
    "print(f\"F1 Macro: {avg_f1_macro:.4f} +/- {std_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c152b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 00:59:06,919 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1804\n",
      "2025-11-13 00:59:06,920 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 00:59:06,920 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 00:59:06,921 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\n",
      "2025-11-13 00:59:06,921 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 00:59:06,921 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 00:59:06,944 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 00:59:06,944 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 00:59:07,192 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 00:59:11,207 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 00:59:11,208\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 00:59:59,922\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0123s.\n",
      "2025-11-13 00:59:59,950 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.042315524218361315, 'weight_decay': 0.025412711464215514, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 64}\n",
      "2025-11-13 00:59:59,951 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 1.289561152458191\n",
      "2025-11-13 00:59:59,951 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.6671001300390117\n",
      "2025-11-13 00:59:59,956 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              8              64  0.042316      0.025413              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0              16          64  \n",
      "2025-11-13 00:59:59,958 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.042315524218361315, 'weight_decay': 0.025412711464215514, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 64}\n",
      "2025-11-13 00:59:59,958 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.042315524218361315, 'weight_decay': 0.025412711464215514, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 16, 'num_epochs': 64}\n",
      "2025-11-13 00:59:59,959 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 00:59:59,959 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:00:00,192 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:00:03,904 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 01:00:04,662 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7477\n",
      "2025-11-13 01:00:04,665 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 01:00:04,670 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 01:00:05,384 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7113\n",
      "2025-11-13 01:00:05,386 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 01:00:05,391 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 01:00:06,115 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.6996\n",
      "2025-11-13 01:00:06,118 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 01:00:06,123 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.7477\n",
      "2025-11-13 01:00:06,123 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.7195\n",
      "2025-11-13 01:00:06,123 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0251\n",
      "2025-11-13 01:00:06,124 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 01:00:06,127 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1805\n",
      "2025-11-13 01:00:06,128 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 01:00:06,128 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 01:00:06,128 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\n",
      "2025-11-13 01:00:06,128 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 01:00:06,129 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 01:00:06,147 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 01:00:06,147 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:00:06,367 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:00:10,059 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 01:00:10,060\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 01:01:13,094\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0034s.\n",
      "2025-11-13 01:01:13,117 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 01:01:13,118 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9271067380905151\n",
      "2025-11-13 01:01:13,118 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 1.0\n",
      "2025-11-13 01:01:13,122 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0             16               8  0.000322      0.018485             128   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128        1024  \n",
      "2025-11-13 01:01:13,123 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 01:01:13,123 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 16, 'gnn_hidden_dim': 8, 'lr': 0.00032218802468455616, 'weight_decay': 0.01848518781681607, 'nn_hidden_dim1': 128, 'nn_hidden_dim2': 128, 'num_epochs': 1024}\n",
      "2025-11-13 01:01:13,124 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 01:01:13,124 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:01:13,347 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:01:17,359 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 01:01:21,677 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 01:01:21,681 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 01:01:21,683 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 01:01:25,836 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.9974\n",
      "2025-11-13 01:01:25,839 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 01:01:25,842 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 01:01:29,885 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 01:01:29,889 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 01:01:29,891 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 01:01:29,891 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.9991\n",
      "2025-11-13 01:01:29,891 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0015\n",
      "2025-11-13 01:01:29,891 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 01:01:29,895 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1806\n",
      "2025-11-13 01:01:29,896 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 01:01:29,896 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 01:01:29,896 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\n",
      "2025-11-13 01:01:29,896 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 01:01:29,896 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 01:01:29,914 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 01:01:29,914 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:01:30,142 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:01:33,858 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 01:01:33,858\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 01:02:25,748\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0123s.\n",
      "2025-11-13 01:02:25,776 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:02:25,776 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9235807061195374\n",
      "2025-11-13 01:02:25,776 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 1.0\n",
      "2025-11-13 01:02:25,781 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              4             128  0.000714      0.012667              64   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128        8192  \n",
      "2025-11-13 01:02:25,783 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:02:25,783 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 4, 'gnn_hidden_dim': 128, 'lr': 0.0007144706406619917, 'weight_decay': 0.012666825542558432, 'nn_hidden_dim1': 64, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:02:25,783 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 01:02:25,784 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:02:26,018 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:02:30,012 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 01:05:12,399 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7425\n",
      "2025-11-13 01:05:12,402 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 01:05:12,410 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 01:07:55,979 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.3602\n",
      "2025-11-13 01:07:55,982 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 01:07:55,990 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 01:10:38,415 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 1.0000\n",
      "2025-11-13 01:10:38,419 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 01:10:38,427 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 1.0000\n",
      "2025-11-13 01:10:38,427 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.7009\n",
      "2025-11-13 01:10:38,427 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.3219\n",
      "2025-11-13 01:10:38,427 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 01:10:38,434 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1807\n",
      "2025-11-13 01:10:38,434 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 01:10:38,435 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 01:10:38,435 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\n",
      "2025-11-13 01:10:38,435 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 01:10:38,435 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 01:10:38,454 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 01:10:38,454 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:10:38,681 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:10:42,334 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 01:10:42,335\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 01:11:26,918\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0026s.\n",
      "2025-11-13 01:11:26,943 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 01:11:26,944 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.9848412871360779\n",
      "2025-11-13 01:11:26,944 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9323797139141743\n",
      "2025-11-13 01:11:26,947 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0              8              64  0.020924      0.009291              16   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128         256  \n",
      "2025-11-13 01:11:26,949 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 01:11:26,950 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 8, 'gnn_hidden_dim': 64, 'lr': 0.020923703325114156, 'weight_decay': 0.009290936416203033, 'nn_hidden_dim1': 16, 'nn_hidden_dim2': 128, 'num_epochs': 256}\n",
      "2025-11-13 01:11:26,950 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 01:11:26,950 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:11:27,185 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:11:31,041 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 01:11:33,806 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.3654\n",
      "2025-11-13 01:11:33,810 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 01:11:33,815 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 01:11:36,589 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.6112\n",
      "2025-11-13 01:11:36,591 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 01:11:36,596 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 01:11:39,333 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.6398\n",
      "2025-11-13 01:11:39,335 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 01:11:39,340 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.6398\n",
      "2025-11-13 01:11:39,340 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.5388\n",
      "2025-11-13 01:11:39,340 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.1508\n",
      "2025-11-13 01:11:39,340 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n",
      "2025-11-13 01:11:39,343 - bioneuralnet.utils.data - INFO - Setting global seed for reproducibility to: 1808\n",
      "2025-11-13 01:11:39,344 - bioneuralnet.utils.data - INFO - CUDA available. Applying seed to all GPU operations\n",
      "2025-11-13 01:11:39,344 - bioneuralnet.utils.data - INFO - Seed setting complete\n",
      "2025-11-13 01:11:39,344 - bioneuralnet.downstream_task.dpmon - INFO - Output directory set to: /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\n",
      "2025-11-13 01:11:39,345 - bioneuralnet.downstream_task.dpmon - INFO - Initialized DPMON with the provided parameters.\n",
      "2025-11-13 01:11:39,345 - bioneuralnet.downstream_task.dpmon - INFO - Starting DPMON run.\n",
      "2025-11-13 01:11:39,363 - bioneuralnet.downstream_task.dpmon - INFO - Running hyperparameter tuning for DPMON.\n",
      "2025-11-13 01:11:39,363 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:11:39,585 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:11:43,559 - bioneuralnet.downstream_task.dpmon - INFO - Starting hyperparameter tuning for dataset shape: (769, 5207)\n",
      "2025-11-13 01:11:43,559\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-11-13 01:12:33,856\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/vicente/ray_results/tune_dp' in 0.0030s.\n",
      "2025-11-13 01:12:33,878 - bioneuralnet.downstream_task.dpmon - INFO - Best trial config: {'gnn_layer_num': 128, 'gnn_hidden_dim': 4, 'lr': 0.0030241037013906107, 'weight_decay': 0.07881291624210075, 'nn_hidden_dim1': 8, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:12:33,879 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final loss: 0.972966194152832\n",
      "2025-11-13 01:12:33,879 - bioneuralnet.downstream_task.dpmon - INFO - Best trial final accuracy: 0.9557867360208062\n",
      "2025-11-13 01:12:33,883 - bioneuralnet.downstream_task.dpmon - INFO -    gnn_layer_num  gnn_hidden_dim        lr  weight_decay  nn_hidden_dim1  \\\n",
      "0            128               4  0.003024      0.078813               8   \n",
      "\n",
      "   nn_hidden_dim2  num_epochs  \n",
      "0             128        8192  \n",
      "2025-11-13 01:12:33,885 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 128, 'gnn_hidden_dim': 4, 'lr': 0.0030241037013906107, 'weight_decay': 0.07881291624210075, 'nn_hidden_dim1': 8, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:12:33,885 - bioneuralnet.downstream_task.dpmon - INFO - Best tuned parameters: {'gnn_layer_num': 128, 'gnn_hidden_dim': 4, 'lr': 0.0030241037013906107, 'weight_decay': 0.07881291624210075, 'nn_hidden_dim1': 8, 'nn_hidden_dim2': 128, 'num_epochs': 8192}\n",
      "2025-11-13 01:12:33,885 - bioneuralnet.downstream_task.dpmon - INFO - Running standard training with tuned parameters.\n",
      "2025-11-13 01:12:33,885 - bioneuralnet.downstream_task.dpmon - INFO - Using GPU 0\n",
      "2025-11-13 01:12:34,123 - bioneuralnet.downstream_task.dpmon - INFO - Number of nodes in network: 5206\n",
      "2025-11-13 01:12:37,923 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 1/3\n",
      "2025-11-13 01:13:11,178 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7503\n",
      "2025-11-13 01:13:11,180 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_1.pth\n",
      "2025-11-13 01:13:11,185 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 2/3\n",
      "2025-11-13 01:13:43,352 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.7061\n",
      "2025-11-13 01:13:43,354 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_2.pth\n",
      "2025-11-13 01:13:43,356 - bioneuralnet.downstream_task.dpmon - INFO - Training iteration 3/3\n",
      "2025-11-13 01:14:15,323 - bioneuralnet.downstream_task.dpmon - INFO - Training Accuracy: 0.8114\n",
      "2025-11-13 01:14:15,326 - bioneuralnet.downstream_task.dpmon - INFO - Model saved to /home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca/dpm_model_iter_3.pth\n",
      "2025-11-13 01:14:15,328 - bioneuralnet.downstream_task.dpmon - INFO - Best Accuracy: 0.8114\n",
      "2025-11-13 01:14:15,328 - bioneuralnet.downstream_task.dpmon - INFO - Average Accuracy across 3 models: 0.7560\n",
      "2025-11-13 01:14:15,328 - bioneuralnet.downstream_task.dpmon - INFO - Standard Deviation across all models: 0.0529\n",
      "2025-11-13 01:14:15,328 - bioneuralnet.downstream_task.dpmon - INFO - Returning best model predictions and average accuracy (predictions, avg_accuracy).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8398 +/- 0.1419\n",
      "F1 Weighted: 0.8008 +/- 0.1781\n",
      "F1 Macro: 0.6495 +/- 0.2936\n"
     ]
    }
   ],
   "source": [
    "output_dir_base_gat = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\")\n",
    "\n",
    "n_repeats = 5\n",
    "all_preds = []\n",
    "\n",
    "for r in range(n_repeats):\n",
    "    bnn.utils.set_seed(SEED+r)\n",
    "    dpmon_repeat = DPMON(\n",
    "        adjacency_matrix=A_train,\n",
    "        omics_list=[dna_meth, rna, mirna],\n",
    "        phenotype_data=target,\n",
    "        clinical_data=clinical_preprocessed,\n",
    "        repeat_num=3,\n",
    "        model='GAT',\n",
    "        tune=True,\n",
    "        gpu=True,\n",
    "        cuda=0,\n",
    "        output_dir=output_dir_base_gat,\n",
    "    )\n",
    "    \n",
    "    predictions_df, _ = dpmon_repeat.run()\n",
    "    all_preds.append(predictions_df[\"Predicted\"].values)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "f1_macro_list = [f1_score(target, pred, average='macro') for pred in all_preds]\n",
    "f1_weighted_list = [f1_score(target, pred, average='weighted') for pred in all_preds]\n",
    "accuracy_list = [accuracy_score(target, pred) for pred in all_preds]\n",
    "\n",
    "avg_f1_macro = np.mean(f1_macro_list)\n",
    "std_f1_macro = np.std(f1_macro_list)\n",
    "\n",
    "avg_f1_weighted = np.mean(f1_weighted_list)\n",
    "std_f1_weighted = np.std(f1_weighted_list)\n",
    "\n",
    "avg_acc = np.mean(accuracy_list)\n",
    "std_acc = np.std(accuracy_list)\n",
    "\n",
    "print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "print(f\"F1 Weighted: {avg_f1_weighted:.4f} +/- {std_f1_weighted:.4f}\")\n",
    "print(f\"F1 Macro: {avg_f1_macro:.4f} +/- {std_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5f085",
   "metadata": {},
   "source": [
    "## Classification Model Training and Evaluation Summary\n",
    "\n",
    "### LogisticRegression: Best Hyperparameters per Seed\n",
    "\n",
    "| Seed | model__C | model__penalty |\n",
    "| :---: | :---: | :---: |\n",
    "| 1804 | 8.40099 | l2 |\n",
    "| 1805 | 14.91826 | l2 |\n",
    "| 1806 | 0.17344 | l2 |\n",
    "| 1807 | 4.16578 | l2 |\n",
    "| 1808 | 0.22553 | l2 |\n",
    "\n",
    "### LogisticRegression: Final Results\n",
    "\n",
    "| Metric | Score |\n",
    "| :---: | :---: |\n",
    "| Accuracy | 0.8486 +/- 0.0115 |\n",
    "| F1 Weighted | 0.8401 +/- 0.0102 |\n",
    "| F1 Macro | 0.7390 +/- 0.0142 |\n",
    "\n",
    "### MLP: Best Hyperparameters per Seed\n",
    "\n",
    "| Seed | model__activation | model__alpha | model__hidden_layer_sizes | model__learning_rate_init |\n",
    "| :---: | :---: | :---: | :---: | :---: |\n",
    "| 1804 | relu | 6.5803 \\mathrm{e}-05 | (50, 50) | 0.000928 |\n",
    "| 1805 | tanh | 0.000868 | (100, 50) | 0.000201 |\n",
    "| 1806 | relu | 0.000209 | (100,) | 0.000121 |\n",
    "| 1807 | tanh | 0.001400 | (100,) | 0.000763 |\n",
    "| 1808 | relu | 0.075812 | (100, 50) | 0.000703 |\n",
    "\n",
    "### MLP: Final Results\n",
    "\n",
    "| Metric | Score |\n",
    "| :---: | :---: |\n",
    "| Accuracy | 0.8134 +/- 0.0178 |\n",
    "| F1 Weighted | 0.8059 +/- 0.0167 |\n",
    "| F1 Macro | 0.6874 +/- 0.0420 |\n",
    "\n",
    "### XGBoost: Best Hyperparameters per Seed\n",
    "\n",
    "| Seed | model__colsample_bytree | model__learning_rate | model__max_depth | model__n_estimators | model__subsample |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 1804 | 0.8 | 0.166 | 1 | 812 | 0.7 |\n",
    "| 1805 | 0.8 | 0.290 | 7 | 933 | 0.7 |\n",
    "| 1806 | 0.9 | 0.229 | 1 | 538 | 0.7 |\n",
    "| 1807 | 0.8 | 0.060 | 1 | 735 | 0.9 |\n",
    "| 1808 | 0.8 | 0.198 | 8 | 837 | 0.9 |\n",
    "\n",
    "### XGBoost: Final Results\n",
    "\n",
    "| Metric | Score |\n",
    "| :---: | :---: |\n",
    "| Accuracy | 0.8390 +/- 0.0091 |\n",
    "| F1 Weighted | 0.8210 +/- 0.0100 |\n",
    "| F1 Macro | 0.7024 +/- 0.0185 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7178390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created X matrix with shape: (769, 5213)\n",
      "Successfully created y vector with shape: (769,)\n",
      "\n",
      "Running Repeat 1/5 (Seed: 1804)\n",
      "Tuning LogisticRegression\n",
      "Best params for LogisticRegression: {'model__C': 8.400991552100372, 'model__penalty': 'l2'}\n",
      "Tuning MLP\n",
      "Best params for MLP: {'model__activation': 'relu', 'model__alpha': 6.580281251856646e-05, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate_init': 0.0009282784959657257}\n",
      "Tuning XGBoost\n",
      "Best params for XGBoost: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.16614177474236685, 'model__max_depth': 8, 'model__n_estimators': 127, 'model__subsample': 0.7}\n",
      "\n",
      "Running Repeat 2/5 (Seed: 1805)\n",
      "Tuning LogisticRegression\n",
      "Best params for LogisticRegression: {'model__C': 14.918264811461304, 'model__penalty': 'l2'}\n",
      "Tuning MLP\n",
      "Best params for MLP: {'model__activation': 'tanh', 'model__alpha': 0.0008678071941085742, 'model__hidden_layer_sizes': (100, 50), 'model__learning_rate_init': 0.00020060261445052188}\n",
      "Tuning XGBoost\n",
      "Best params for XGBoost: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.29067472468993266, 'model__max_depth': 9, 'model__n_estimators': 338, 'model__subsample': 0.7}\n",
      "\n",
      "Running Repeat 3/5 (Seed: 1806)\n",
      "Tuning LogisticRegression\n",
      "Best params for LogisticRegression: {'model__C': 0.17343546454096814, 'model__penalty': 'l2'}\n",
      "Tuning MLP\n",
      "Best params for MLP: {'model__activation': 'relu', 'model__alpha': 0.00020899398799679073, 'model__hidden_layer_sizes': (100,), 'model__learning_rate_init': 0.00012083615933434813}\n",
      "Tuning XGBoost\n",
      "Best params for XGBoost: {'model__colsample_bytree': 0.9, 'model__learning_rate': 0.22911409388486595, 'model__max_depth': 5, 'model__n_estimators': 383, 'model__subsample': 0.7}\n",
      "\n",
      "Running Repeat 4/5 (Seed: 1807)\n",
      "Tuning LogisticRegression\n",
      "Best params for LogisticRegression: {'model__C': 4.165776290707449, 'model__penalty': 'l2'}\n",
      "Tuning MLP\n",
      "Best params for MLP: {'model__activation': 'tanh', 'model__alpha': 0.001400214477936158, 'model__hidden_layer_sizes': (100,), 'model__learning_rate_init': 0.0007628203936932214}\n",
      "Tuning XGBoost\n",
      "Best params for XGBoost: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.060058687986192134, 'model__max_depth': 7, 'model__n_estimators': 359, 'model__subsample': 0.7}\n",
      "\n",
      "Running Repeat 5/5 (Seed: 1808)\n",
      "Tuning LogisticRegression\n",
      "Best params for LogisticRegression: {'model__C': 0.22553303102466327, 'model__penalty': 'l2'}\n",
      "Tuning MLP\n",
      "Best params for MLP: {'model__activation': 'relu', 'model__alpha': 0.07581193053003465, 'model__hidden_layer_sizes': (100, 50), 'model__learning_rate_init': 0.0007030024974217881}\n",
      "Tuning XGBoost\n",
      "Best params for XGBoost: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.19880584274888335, 'model__max_depth': 8, 'model__n_estimators': 378, 'model__subsample': 0.9}\n",
      "Tuned Model Results (Averaged over 5 runs)\n",
      "(Tuning was 10 iterations with 3fold CV)\n",
      "Results for LogisticRegression:\n",
      "Accuracy: 0.8486 +/- 0.0115\n",
      "F1 Weighted: 0.8401 +/- 0.0102\n",
      "F1 Macro: 0.7390 +/- 0.0142\n",
      "Results for MLP:\n",
      "Accuracy: 0.8134 +/- 0.0178\n",
      "F1 Weighted: 0.8059 +/- 0.0167\n",
      "F1 Macro: 0.6874 +/- 0.0420\n",
      "Results for XGBoost:\n",
      "Accuracy: 0.8390 +/- 0.0091\n",
      "F1 Weighted: 0.8210 +/- 0.0100\n",
      "F1 Macro: 0.7024 +/- 0.0185\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "X = pd.concat([dna_meth, rna, mirna, clinical_preprocessed], axis=1)\n",
    "y = target['phenotype']\n",
    "print(f\"Successfully created X matrix with shape: {X.shape}\")\n",
    "print(f\"Successfully created y vector with shape: {y.shape}\")\n",
    "\n",
    "all_results = {\n",
    "    \"LogisticRegression\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "    \"MLP\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "    \"XGBoost\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "}\n",
    "\n",
    "all_results = {\n",
    "    \"LogisticRegression\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "    \"MLP\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "    \"XGBoost\": {\"acc\": [], \"f1_w\": [], \"f1_m\": []},\n",
    "}\n",
    "\n",
    "N_REPEATS = 5\n",
    "TEST_SPLIT_SIZE = .7\n",
    "CV_FOLDS = 3\n",
    "N_ITER_SEARCH = 10\n",
    "\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        penalty=None \n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([('scaler', StandardScaler()),\n",
    "    ('model', MLPClassifier(\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=10\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([('scaler', StandardScaler()),\n",
    "    ('model', XGBClassifier(\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "params_lr = {\n",
    "    'model__penalty': ['l2'], \n",
    "    'model__C': loguniform(1e-4, 1e2)\n",
    "}\n",
    "\n",
    "params_mlp = {\n",
    "    'model__hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': loguniform(1e-5, 1e-1),\n",
    "    'model__learning_rate_init': loguniform(1e-4, 1e-2)\n",
    "}\n",
    "\n",
    "params_xgb = {\n",
    "    'model__n_estimators': randint(100, 500),\n",
    "    'model__learning_rate': loguniform(0.01, 0.3),\n",
    "    'model__max_depth': randint(3, 10),\n",
    "    'model__subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "models_to_tune = {\n",
    "    \"LogisticRegression\": (pipe_lr, params_lr),\n",
    "    \"MLP\": (pipe_mlp, params_mlp),\n",
    "    \"XGBoost\": (pipe_xgb, params_xgb)\n",
    "}\n",
    "\n",
    "for r in range(N_REPEATS):\n",
    "    seed = SEED + r\n",
    "    print(f\"\\nRunning Repeat {r+1}/{N_REPEATS} (Seed: {seed})\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=TEST_SPLIT_SIZE, \n",
    "        random_state=seed, \n",
    "        stratify=y)\n",
    "    \n",
    "    cv_splitter = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=seed)\n",
    "    for name, (pipeline, params) in models_to_tune.items():\n",
    "        print(f\"Tuning {name}\")\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_distributions=params,\n",
    "            n_iter=N_ITER_SEARCH,\n",
    "            cv=cv_splitter,\n",
    "            scoring='f1_weighted',\n",
    "            n_jobs=-1,\n",
    "            random_state=seed\n",
    "        )\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            search.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Best params for {name}: {search.best_params_}\")\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        preds = best_model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1_w = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
    "        f1_m = f1_score(y_test, preds, average='macro', zero_division=0)\n",
    "\n",
    "        all_results[name][\"acc\"].append(acc)\n",
    "        all_results[name][\"f1_w\"].append(f1_w)\n",
    "        all_results[name][\"f1_m\"].append(f1_m)\n",
    "\n",
    "print(f\"Tuned Model Results (Averaged over {N_REPEATS} runs)\")\n",
    "print(f\"(Tuning was {N_ITER_SEARCH} iterations with {CV_FOLDS}fold CV)\")\n",
    "\n",
    "for model_name, metrics in all_results.items():\n",
    "    avg_acc = np.mean(metrics[\"acc\"])\n",
    "    std_acc = np.std(metrics[\"acc\"])\n",
    "    \n",
    "    avg_f1_w = np.mean(metrics[\"f1_w\"])\n",
    "    std_f1_w = np.std(metrics[\"f1_w\"])\n",
    "    \n",
    "    avg_f1_m = np.mean(metrics[\"f1_m\"])\n",
    "    std_f1_m = np.std(metrics[\"f1_m\"])\n",
    "\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    print(f\"F1 Weighted: {avg_f1_w:.4f} +/- {std_f1_w:.4f}\")\n",
    "    print(f\"F1 Macro: {avg_f1_m:.4f} +/- {std_f1_m:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63a116",
   "metadata": {},
   "source": [
    "## run cell below number are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2055b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "gnn_plot_data = {\n",
    "    \"Accuracy\": {\n",
    "        \"SAGE\": (0.9774, 0.0190),\n",
    "        \"GCN\": (0.9009, 0.1238),\n",
    "        \"GAT\": (0.8398, 0.1419)\n",
    "    },\n",
    "    \"F1 Weighted\": {\n",
    "        \"SAGE\": (0.9684, 0.0286),\n",
    "        \"GCN\": (0.8697, 0.1673),\n",
    "        \"GAT\": (0.8008, 0.1781)\n",
    "    },\n",
    "    \"F1 Macro\": {\n",
    "        \"SAGE\": (0.8957, 0.1017),\n",
    "        \"GCN\": (0.7880, 0.2738),\n",
    "        \"GAT\": (0.6495, 0.2936)\n",
    "    }\n",
    "}\n",
    "\n",
    "baseline_plot_data = {\n",
    "    \"Accuracy\": {\n",
    "        \"SAGE\": (0.9774, 0.0190),\n",
    "        \"LogReg\": (0.8486, 0.0115),\n",
    "        \"XGBoost\": (0.8390, 0.0091),\n",
    "        \"MLP\": (0.8134, 0.0178)\n",
    "    },\n",
    "    \"F1 Weighted\": {\n",
    "        \"SAGE\": (0.9684, 0.0286),\n",
    "        \"LogReg\": (0.8401, 0.0102),\n",
    "        \"XGBoost\": (0.8210, 0.0100),\n",
    "        \"MLP\": (0.8059, 0.0167)\n",
    "    },\n",
    "    \"F1 Macro\": {\n",
    "        \"SAGE\": (0.8957, 0.1017),\n",
    "        \"LogReg\": (0.7390, 0.0142),\n",
    "        \"XGBoost\": (0.7024, 0.0185),\n",
    "        \"MLP\": (0.6874, 0.0420)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "bnn.metrics.plot_multiple_metrics(\n",
    "    gnn_plot_data,\n",
    "    title_map={\n",
    "        \"Accuracy\": \"GNNs Comparison: Accuracy\",\n",
    "        \"F1 Weighted\": \"GNNs Comparison: F1 Weighted\",\n",
    "        \"F1 Macro\": \"GNNs Comparison: F1 Macro\"\n",
    "    }\n",
    ")\n",
    "\n",
    "bnn.metrics.plot_multiple_metrics(\n",
    "    baseline_plot_data,\n",
    "    title_map={\n",
    "        \"Accuracy\": \"SAGE vs. Baselines: Accuracy\",\n",
    "        \"F1 Weighted\": \"SAGE vs. Baselines: F1 Weighted\",\n",
    "        \"F1 Macro\": \"SAGE vs. Baselines: F1 Macro\"\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
