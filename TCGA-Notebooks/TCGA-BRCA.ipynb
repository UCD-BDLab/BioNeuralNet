{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d182cc95",
   "metadata": {},
   "source": [
    "# TCGA-BRCA Analysis: *Cancer Subtype* classification\n",
    "\n",
    "### Dataset Source\n",
    "\n",
    "- **Omics Data**: [FireHose BRCA](http://firebrowse.org/?cohort=BRCA)\n",
    "- **Clinical and PAM50 Data**: [TCGAbiolinks](http://bioconductor.org/packages/release/bioc/html/TCGAbiolinks.html)\n",
    "\n",
    "##### Dataset Overview\n",
    "\n",
    "- **Original Data**:\n",
    "\n",
    "    - **Methylation**: 20,107 × 885\n",
    "    - **mRNA**: 18,321 × 1,212\n",
    "    - **miRNA**: 503 × 1,189\n",
    "    - **PAM50**: 1,087 × 1\n",
    "    - **Clinical**: 1,098 × 101\n",
    "\n",
    "- **PAM50 Subtype Counts**:\n",
    "\n",
    "    - **LumA**: 419\n",
    "    - **LumB**: 140\n",
    "    - **Basal**: 130\n",
    "    - **Her2**: 46\n",
    "    - **Normal**: 34\n",
    "\n",
    "### Patients in Every Dataset\n",
    "\n",
    "- Total patients present in methylation, mRNA, miRNA, PAM50, and clinical: **769**\n",
    "\n",
    "### Final Shapes (Per-Patient)\n",
    "\n",
    "After aggregating multiple aliquots by mean, all modalities align on 769 patients:\n",
    "\n",
    "- **Methylation**: 769 × 20,106\n",
    "- **mRNA**: 769 × 20,531\n",
    "- **miRNA**: 769 × 503\n",
    "- **PAM50**: 769 × 1\n",
    "- **Clinical**: 769 × 119\n",
    "\n",
    "### Data Summary Table\n",
    "\n",
    "| Stage                          | Clinical    | Methylation  | miRNA       | mRNA           | PAM50 (Subtype Counts)                                         | Notes                                   |\n",
    "| ------------------------------ | ----------- | ------------ | ----------- | -------------- | -------------------------------------------------------------- | --------------------------------------- |\n",
    "| **Original Raw Data**          | 1,098 × 101 | 20,107 × 885 | 503 × 1,189 | 18,321 × 1,212 | LumA: 509<br>LumB: 209<br>Basal: 192<br>Her2: 82<br>Normal: 40 | Raw FireHose & TCGAbiolinks files       |\n",
    "| **Patient-Level Intersection** | 769 × 101   | 769 × 20,107 | 769 × 1,046 | 769 × 20,531   | LumA: 419<br>LumB: 140<br>Basal: 130<br>Her2: 46<br>Normal: 34 | Patients with complete data in all sets |\n",
    "\n",
    "### Reference Links\n",
    "\n",
    "- [FireHose BRCA](http://firebrowse.org/?cohort=BRCA)\n",
    "- [TCGAbiolinks](http://bioconductor.org/packages/release/bioc/html/TCGAbiolinks.html)\n",
    "- [Direct Download BRCA](http://firebrowse.org/?cohort=BRCA&download_dialog=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "root = Path(\"/home/vicente/Github/BioNeuralNet/TCGA_BRCA_DATA\")\n",
    "\n",
    "mirna_raw = pd.read_csv(root/\"BRCA.miRseq_RPKM_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)                            \n",
    "rna_raw = pd.read_csv(root / \"BRCA.uncv2.mRNAseq_RSEM_normalized_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)\n",
    "meth_raw = pd.read_csv(root/\"BRCA.meth.by_mean.data.txt\", sep='\\t',index_col=0,low_memory=False)\n",
    "clinical_raw = pd.read_csv(root / \"BRCA.clin.merged.picked.txt\",sep=\"\\t\", index_col=0, low_memory=False)\n",
    "\n",
    "# display all shapes and first few rows of each dataset\n",
    "display(mirna_raw.iloc[:3,:5])\n",
    "display(mirna_raw.shape)\n",
    "\n",
    "display(rna_raw.iloc[:3,:5])\n",
    "display(rna_raw.shape)\n",
    "\n",
    "display(meth_raw.iloc[:3,:5])\n",
    "display(meth_raw.shape)\n",
    "\n",
    "display(clinical_raw.iloc[:3,:5])\n",
    "display(clinical_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacae339",
   "metadata": {},
   "source": [
    "## TCGA-BioLink: Pam50\n",
    "\n",
    "This section demonstrates how to use the `TCGAbiolinks` R package to access and download clinical and molecular subtype data. It begins by ensuring `TCGAbiolinks` is installed, then loads the package. It retrieves PAM50 molecular subtype labels using `TCGAquery_subtype()` and writes them to a CSV file. Additionally, it downloads clinical data using `GDCquery_clinic()` and formats it with `GDCprepare_clinic()`, saving the result as another CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445601f",
   "metadata": {},
   "source": [
    "```R\n",
    "  # Install TCGAbiolinks\n",
    "  if (!requireNamespace(\"TCGAbiolinks\", quietly = TRUE)) {\n",
    "    if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "      install.packages(\"BiocManager\")\n",
    "    BiocManager::install(\"TCGAbiolinks\")\n",
    "  }\n",
    "\n",
    "  # Load the library\n",
    "  library(TCGAbiolinks)\n",
    "\n",
    "  # Download PAM50 subtype labels\n",
    "  pam50_df <- TCGAquery_subtype(tumor = \"BRCA\")[ , c(\"patient\", \"BRCA_Subtype_PAM50\")]\n",
    "  write.csv(pam50_df, file = \"BRCA_PAM50_labels.csv\", row.names = FALSE, quote = FALSE)\n",
    "\n",
    "  # Download clinical data\n",
    "  clin_raw <- GDCquery_clinic(project = \"TCGA-BRCA\", type = \"clinical\")\n",
    "  clin_df <- GDCprepare_clinic(clin_raw, clinical.info = \"patient\")\n",
    "  write.csv(clin_df, file = \"BRCA_clinical_data.csv\", row.names = FALSE, quote = FALSE)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6eb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pam50 = pd.read_csv(root /\"BRCA_PAM50_labels.csv\",index_col=0)\n",
    "clinical_biolinks = pd.read_csv(root /\"BRCA_clinical_data.csv\",index_col=1)\n",
    "\n",
    "display(pam50.iloc[:5,:5])\n",
    "display(pam50.shape)\n",
    "display(clinical_biolinks.iloc[:5,:5])\n",
    "display(clinical_biolinks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd066d50",
   "metadata": {},
   "source": [
    "## Data Processing Summary\n",
    "\n",
    "- **Transpose Data**: All raw data (miRNA, RNA, etc.) is flipped so rows represent patients and columns represent features.\n",
    "- **Standardize Patient IDs**: Patient IDs in all tables are cleaned to the 12-character TCGA format (e.g., `TCGA-AB-1234`) for matching.\n",
    "- **Handle Duplicates**: Duplicate patient rows are averaged in the omics data. The first entry is kept for duplicate patients in the clinical data.\n",
    "- **Impute Missing Values (KNN)**: Missing data (NaNs) in the omics datasets are estimated and filled using **K-Nearest Neighbors (KNN)** imputation.\n",
    "- **Find Common Patients**: The script identifies the largest common cohort of patients that exist in all datasets.\n",
    "- **Subset Data**: All data tables are filtered down to only this common list of patients, ensuring perfect alignment.\n",
    "- **Extract Target**: The **PAM50 subtype** column is pulled from the corresponding data table to be used as the final prediction target (y-variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "meth = meth_raw.T\n",
    "rna = rna_raw.T\n",
    "mirna = mirna_raw.T\n",
    "clinical_firehose = clinical_raw.T\n",
    "\n",
    "print(f\"miRNA (samples, features): {mirna.shape}\")\n",
    "print(f\"RNA (samples, features): {rna.shape}\")\n",
    "print(f\"Methylation (samples, features): {meth.shape}\")\n",
    "print(f\"Clinical (samples, features): {clinical_firehose.shape}\")\n",
    "\n",
    "def trim_barcode(idx):\n",
    "    return idx.to_series().str.slice(0, 12)\n",
    "\n",
    "# standardize patient IDs across all files\n",
    "meth.index = trim_barcode(meth.index)\n",
    "rna.index = trim_barcode(rna.index)\n",
    "mirna.index = trim_barcode(mirna.index)\n",
    "clinical_firehose.index = clinical_firehose.index.str.upper()\n",
    "clinical_firehose.index.name = \"Patient_ID\"\n",
    "\n",
    "meth = meth.apply(pd.to_numeric, errors='coerce')\n",
    "meth = meth.drop(columns=[\"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "rna = rna.apply(pd.to_numeric, errors='coerce')\n",
    "mirna = mirna.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "meth = meth.groupby(meth.index).mean()\n",
    "rna = rna.groupby(rna.index).mean()\n",
    "mirna = mirna.groupby(mirna.index).mean()\n",
    "\n",
    "clinical = clinical_firehose[~clinical_firehose.index.duplicated(keep='first')]\n",
    "\n",
    "for df in [meth, rna, mirna]:\n",
    "    df.columns = df.columns.str.replace(r\"\\?\", \"unknown_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"\\|\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(\"-\", \"_\", regex=False)\n",
    "    df.columns = df.columns.str.replace(r\"_+\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.strip(\"_\")\n",
    "\n",
    "print(f\"\\nMethylation shape: {meth.shape}\")\n",
    "print(f\"RNA shape: {rna.shape}\")\n",
    "print(f\"miRNA shape: {mirna.shape}\")\n",
    "print(f\"Clinical shape: {clinical.shape}\")\n",
    "\n",
    "meth.columns = pd.Index(meth.columns.tolist())\n",
    "rna.columns = pd.Index(rna.columns.tolist())\n",
    "mirna.columns = pd.Index(mirna.columns.tolist())\n",
    "\n",
    "# impute missing values using KNN on the finalized omics data\n",
    "meth = bnn.utils.data.impute_omics_knn(meth, n_neighbors=5)\n",
    "rna = bnn.utils.data.impute_omics_knn(rna, n_neighbors=5)\n",
    "mirna = bnn.utils.data.impute_omics_knn(mirna, n_neighbors=5)\n",
    "\n",
    "# handle duplicate patient IDs in clinical data (keeping first occurrence)\n",
    "clinical_biolinks = clinical_biolinks[~clinical_biolinks.index.duplicated(keep='first')]\n",
    "clinical_firehose = clinical_firehose[~clinical_firehose.index.duplicated(keep='first')]\n",
    "\n",
    "# patients common to both clinical sources and merge\n",
    "common_clinical_patients = clinical_biolinks.index.intersection(clinical_firehose.index)\n",
    "clinical_biolinks = clinical_biolinks.loc[common_clinical_patients]\n",
    "clinical_firehose = clinical_firehose.loc[common_clinical_patients]\n",
    "clinical = pd.concat([clinical_biolinks, clinical_firehose], axis=1)\n",
    "clinical.index.name = \"Patient_ID\"\n",
    "\n",
    "\n",
    "# final list of patients present in ALL datasets\n",
    "common_patients = sorted(\n",
    "    set(meth.index) & \n",
    "    set(rna.index) & \n",
    "    set(mirna.index) & \n",
    "    set(pam50.index) & \n",
    "    set(clinical.index)\n",
    ")\n",
    "\n",
    "print(f\"\\nFound: {len(common_patients)} patients across all data types.\")\n",
    "\n",
    "meth = meth.loc[common_patients]\n",
    "rna = rna.loc[common_patients]\n",
    "mirna = mirna.loc[common_patients]\n",
    "pam50 = pam50.loc[common_patients]\n",
    "clinical = clinical.loc[common_patients]\n",
    "\n",
    "\n",
    "targets = pam50['BRCA_Subtype_PAM50'] \n",
    "\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"meth: {meth.shape}\")\n",
    "print(f\"rna: {rna.shape}\")\n",
    "print(f\"mirna: {mirna.shape}\")\n",
    "print(f\"pam50: {pam50.shape}\")\n",
    "print(f\"clinical: {clinical.shape}\")\n",
    "print(f\"targets: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee114802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns from clinical data\n",
    "clinical.drop(columns=[\"Composite Element REF\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "# we transform the methylation beta values to M-values and drop unwanted columns\n",
    "meth_m = meth.drop(columns=[\"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "# convert beta values to M-values using bioneuralnet utility with small epsilon to avoid log(0)\n",
    "meth_m = bnn.utils.beta_to_m(meth_m, eps=1e-6) \n",
    "\n",
    "# lastly we turn the target labels into numerical classes\n",
    "mapping_brca = {\n",
    "    'LumA': 0, \n",
    "    'Her2': 1, \n",
    "    'LumB': 2, \n",
    "    'Basal': 3, \n",
    "    'Normal': 4\n",
    "}\n",
    "target_labels = targets.map(mapping_brca).to_frame(name=\"target\")\n",
    "\n",
    "X_meth = meth_m.loc[targets.index]\n",
    "X_rna = rna.loc[targets.index]\n",
    "X_mirna = mirna.loc[targets.index]\n",
    "Y_labels = target_labels.loc[targets.index]\n",
    "clinical_processed = clinical.loc[targets.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_meth.iloc[:3,:5])\n",
    "display(X_meth.shape)\n",
    "\n",
    "display(X_rna.iloc[:3,:5])\n",
    "display(X_rna.shape)\n",
    "\n",
    "display(X_mirna.iloc[:3,:5])\n",
    "display(X_mirna.shape)\n",
    "\n",
    "display(clinical_processed.iloc[:3,:5])\n",
    "display(clinical_processed.shape)\n",
    "\n",
    "display(Y_labels.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09265512",
   "metadata": {},
   "source": [
    "## Feature Selection Methodology for BRCA\n",
    "\n",
    "### Supported Methods and Interpretation\n",
    "\n",
    "BioNeuralNet provides three techniques for feature selection, allowing for different views of the data's statistical profile:\n",
    "\n",
    "* Variance Thresholding: Identifies features with the highest overall variance across all samples.\n",
    "\n",
    "* ANOVA F-test: Pinpoints features that best distinguish between the target classes (LumA, LumB, Her2, Basal, and Normal).\n",
    "\n",
    "    Random Forest Importance: Assesses feature utility based on its contribution to a predictive non-linear model.\n",
    "\n",
    "### BRCA Cohort Selection Strategy\n",
    "\n",
    "A dimensionality reduction step was essential for managing the high-feature-count omics data, given the complexity of the BRCA network:\n",
    "\n",
    "* High-Feature Datasets: Both DNA Methylation (20,106 features) and RNA (18,321 features) required significant feature reduction.\n",
    "\n",
    "* Filtering Process: The top 6,000 features were initially extracted from the Methylation and RNA datasets using all three methods.\n",
    "\n",
    "* Final Set: A consensus set was built by finding the intersection of features selected by the ANOVA F-test and Random Forest Importance, ensuring both statistical relevance and model-based utility.\n",
    "\n",
    "* Low-Feature Datasets: The miRNA data (503 features) was passed through without selection, as its feature count was already manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "# feature selection\n",
    "meth_highvar = bnn.utils.select_top_k_variance(X_meth, k=6000)\n",
    "rna_highvar = bnn.utils.select_top_k_variance(X_rna, k=6000)\n",
    "\n",
    "meth_af = bnn.utils.top_anova_f_features(X_meth, Y_labels, max_features=6000)\n",
    "rna_af = bnn.utils.top_anova_f_features(X_rna, Y_labels, max_features=6000)\n",
    "\n",
    "meth_rf = bnn.utils.select_top_randomforest(X_meth, Y_labels, top_k=6000)\n",
    "rna_rf = bnn.utils.select_top_randomforest(X_rna, Y_labels, top_k=6000)\n",
    "\n",
    "meth_var_set = set(meth_highvar.columns)\n",
    "meth_anova_set = set(meth_af.columns)\n",
    "meth_rf_set = set(meth_rf.columns)\n",
    "\n",
    "rna_var_set = set(rna_highvar.columns)\n",
    "rna_anova_set = set(rna_af.columns)\n",
    "rna_rf_set = set(rna_rf.columns)\n",
    "\n",
    "meth_inter1 = list(meth_anova_set & meth_var_set)\n",
    "meth_inter2 = list(meth_rf_set & meth_var_set)\n",
    "meth_inter3 = list(meth_anova_set & meth_rf_set)\n",
    "meth_all_three = list(meth_anova_set & meth_var_set & meth_rf_set)\n",
    "\n",
    "rna_inter4 = list(rna_anova_set & rna_var_set)\n",
    "rna_inter5 = list(rna_rf_set & rna_var_set)\n",
    "rna_inter6 = list(rna_anova_set & rna_rf_set)\n",
    "rna_all_three = list(rna_anova_set & rna_var_set & rna_rf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc981cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FROM THE 6000 Methylation feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(meth_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(meth_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(meth_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(meth_all_three)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da639dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFROM THE 6000 RNA feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(rna_inter4)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(rna_inter5)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(rna_inter6)} features\")\n",
    "print(f\"All three methods agree on: {len(rna_all_three)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6d4a4",
   "metadata": {},
   "source": [
    "## Feature Selection Summary: ANOVA-RF Intersection\n",
    "\n",
    "The final set of features was determined by the **intersection** of those highlighted by the **ANOVA F-test** and **Random Forest Importance**. This methodology provides a balanced filter, capturing features with both high class-separability (ANOVA) and significant predictive value in a non-linear model (Random Forest). The resulting feature pool is considered highly relevant for the subsequent modeling tasks.\n",
    "\n",
    "### Feature Overlap Results\n",
    "\n",
    "The table below quantifies the shared features identified by the different selection techniques for each omics type.\n",
    "\n",
    "| Omics Data Type | ANOVA-F & Variance | RF & Variance | ANOVA-F & Random Forest (Selected) | All Three Agree |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Methylation** | 2,092 features | 1,870 features | **2,203 features** | 814 features |\n",
    "| **RNA** | 2,359 features | 2,191 features | **2,500 features** | 1,124 features |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc89f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meth_selected = X_meth[meth_inter3]\n",
    "X_rna_selected = X_rna[rna_inter6]\n",
    "\n",
    "print(\"\\nFinal Shapes for Modeling\")\n",
    "print(f\"Methylation (X1): {X_meth_selected.shape}\")\n",
    "print(f\"RNA-Seq (X2): {X_rna_selected.shape}\")\n",
    "print(f\"miRNA-Seq (X3): {X_mirna.shape}\")\n",
    "print(f\"Labels (Y): {Y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2168980",
   "metadata": {},
   "source": [
    "## Data Availability\n",
    "\n",
    "To facilitate rapid experimentation and reproduction of our results, the fully processed and feature-selected dataset used in this analysis has been made available directly within the package.\n",
    "\n",
    "Users can load this dataset, bypassing all preceding data acquisition, preprocessing, and feature selection steps. This allows users to proceed immediately from this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0340f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.datasets import DatasetLoader\n",
    "\n",
    "tgca_brca = DatasetLoader(\"brca\")\n",
    "display(tgca_brca.shape)\n",
    "\n",
    "dna_meth = tgca_brca[\"meth\"]\n",
    "rna = tgca_brca[\"rna\"]\n",
    "mirna = tgca_brca[\"mirna\"]\n",
    "clinical = tgca_brca[\"clinical\"]\n",
    "target = tgca_brca[\"target\"]\n",
    "\n",
    "display(dna_meth.iloc[:3,:5])\n",
    "display(rna.iloc[:3,:5])\n",
    "display(mirna.iloc[:3,:5])\n",
    "display(clinical.iloc[:3,:5])\n",
    "display(target.iloc[:3,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bioneuralnet as bnn\n",
    "\n",
    "# subset from dna_methylation and rna to reduce dimensionality from 5000+ to 2525\n",
    "dna_meth = bnn.utils.select_top_k_variance(dna_meth, k=1011)\n",
    "rna = bnn.utils.select_top_k_variance(rna, k=1011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d776c",
   "metadata": {},
   "source": [
    "## Reproducibility and Seeding\n",
    "\n",
    "To ensure our experimental results are fully reproducible, a single global seed is set at the beginning of the analysis.\n",
    "\n",
    "This utility function propagates the seed to all sources of randomness, including `random`, `numpy`, and `torch` (for both CPU and GPU). Critically, it also configures the PyTorch cuDNN backend to use deterministic algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "SEED = 8183\n",
    "bnn.utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b161bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identified several columns in the clinical data that could lead to data leakage\n",
    "dataleak_columns = [\n",
    "    'treatments_pharmaceutical_days_to_treatment_end',\n",
    "    'treatments_pharmaceutical_days_to_treatment_start',\n",
    "    'treatments_pharmaceutical_treatment_id',\n",
    "    'treatments_pharmaceutical_treatment_type',\n",
    "    'treatments_pharmaceutical_regimen_or_line_of_therapy',\n",
    "    'treatments_pharmaceutical_treatment_effect',\n",
    "    'treatments_pharmaceutical_therapeutic_agents',\n",
    "    'treatments_pharmaceutical_treatment_or_therapy',\n",
    "    'treatments_pharmaceutical_initial_disease_status',\n",
    "    'treatments_pharmaceutical_treatment_intent_type',\n",
    "    'treatments_pharmaceutical_treatment_anatomic_site',\n",
    "    'treatments_pharmaceutical_treatment_outcome',\n",
    "    'treatments_pharmaceutical_prescribed_dose_units',\n",
    "    'treatments_pharmaceutical_treatment_dose',\n",
    "    'treatments_pharmaceutical_route_of_administration',\n",
    "    'treatments_pharmaceutical_number_of_cycles',\n",
    "    'treatments_pharmaceutical_prescribed_dose',\n",
    "    'treatments_pharmaceutical_treatment_dose_units',\n",
    "    'treatments_pharmaceutical_clinical_trial_indicator',\n",
    "    'treatments_pharmaceutical_treatment_anatomic_sites',\n",
    "    'treatments_pharmaceutical_margin_status',\n",
    "    'treatments_pharmaceutical_course_number',\n",
    "    'treatments_pharmaceutical_number_of_fractions',\n",
    "    'treatments_radiation_days_to_treatment_end',\n",
    "    'treatments_radiation_days_to_treatment_start',\n",
    "    'treatments_radiation_treatment_id',\n",
    "    'treatments_radiation_treatment_type',\n",
    "    'treatments_radiation_regimen_or_line_of_therapy',\n",
    "    'treatments_radiation_treatment_effect',\n",
    "    'treatments_radiation_therapeutic_agents',\n",
    "    'treatments_radiation_treatment_or_therapy',\n",
    "    'treatments_radiation_initial_disease_status',\n",
    "    'treatments_radiation_treatment_intent_type',\n",
    "    'treatments_radiation_treatment_anatomic_site',\n",
    "    'treatments_radiation_treatment_outcome',\n",
    "    'treatments_radiation_prescribed_dose_units',\n",
    "    'treatments_radiation_treatment_dose',\n",
    "    'treatments_radiation_route_of_administration',\n",
    "    'treatments_radiation_number_of_cycles',\n",
    "    'treatments_radiation_prescribed_dose',\n",
    "    'treatments_radiation_treatment_dose_units',\n",
    "    'treatments_radiation_clinical_trial_indicator',\n",
    "    'treatments_radiation_treatment_anatomic_sites',\n",
    "    'treatments_radiation_margin_status',\n",
    "    'treatments_radiation_course_number',\n",
    "    'treatments_radiation_number_of_fractions',\n",
    "    'radiation_therapy',\n",
    "    'patient',\n",
    "    'ajcc_pathologic_stage',\n",
    "    'ajcc_pathologic_t',\n",
    "    'ajcc_pathologic_n',\n",
    "    'ajcc_pathologic_m',\n",
    "    'age_at_diagnosis',\n",
    "    'primary_diagnosis',\n",
    "   'tissue_or_organ_of_origin',\n",
    "    'days_to_last_follow_up',\n",
    "    'year_of_diagnosis',\n",
    "    \n",
    "    'vital_status',\n",
    "    'days_to_death',\n",
    "    'year_of_death',\n",
    "    'days_to_last_follow_up',\n",
    "    'days_to_last_known_alive',\n",
    "    'last_known_disease_status',\n",
    "    'days_to_last_known_disease_status',\n",
    "    'days_to_recurrence',\n",
    "    'progression_or_recurrence',\n",
    "    'age_at_diagnosis',\n",
    "    'days_to_birth',  \n",
    "]\n",
    "\n",
    "clinical_clean = clinical.drop(columns=dataleak_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import preprocess_clinical\n",
    "\n",
    "clinical_for_model = preprocess_clinical(\n",
    "    clinical_clean, \n",
    "    top_k=7, \n",
    "    scale=False,\n",
    ")\n",
    "\n",
    "print(clinical_for_model.columns)\n",
    "display(clinical_for_model.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b099471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import gen_threshold_graph, gen_correlation_graph, gen_similarity_graph, gen_gaussian_knn_graph\n",
    "\n",
    "omics_brca = pd.concat([dna_meth, rna, mirna], axis=1)\n",
    "\n",
    "threshold_10 = gen_threshold_graph(omics_brca, b=6.2, k=10)\n",
    "correlation_10 = gen_correlation_graph(omics_brca, k=10, method='pearson', signed=False)\n",
    "similarity_10 = gen_similarity_graph(omics_brca, k=10, metric='cosine')\n",
    "gaussian_15 = gen_gaussian_knn_graph(omics_brca, k=15, sigma=None)\n",
    "\n",
    "comparison_runs = [\n",
    "    {\"name\":\"threshold_10\", \"graph\": threshold_10},\n",
    "    {\"name\":\"correlation_10\", \"graph\": correlation_10},\n",
    "    {\"name\":\"similarity_10\", \"graph\": similarity_10},\n",
    "    {\"name\":\"gaussian_15\", \"graph\": gaussian_15},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4e2c7",
   "metadata": {},
   "source": [
    "## Classification using DPMON: Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/brca\")\n",
    "all_results = []\n",
    "\n",
    "for run_config in comparison_runs:\n",
    "    graph_name = run_config[\"name\"]\n",
    "    A_full = run_config[\"graph\"]\n",
    "    \n",
    "    current_output_dir = output_dir_base / graph_name\n",
    "    current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dpmon_params_base = {\n",
    "        \"adjacency_matrix\": A_full,\n",
    "        \"omics_list\": omics_brca,\n",
    "        \"phenotype_data\": target,\n",
    "        \"phenotype_col\": \"target\",\n",
    "        \"clinical_data\": clinical_for_model,\n",
    "        \"model\": 'GAT',\n",
    "        \"tune\": True, \n",
    "        \"cv\": True,   \n",
    "        \"n_folds\": 5,\n",
    "        \"repeat_num\":5,\n",
    "        \"gpu\": True,\n",
    "        \"cuda\": 0,\n",
    "        \"seed\": SEED,\n",
    "        \"output_dir\": current_output_dir\n",
    "    }\n",
    "    \n",
    "    dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "    predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "\n",
    "    all_results.append({\n",
    "        \"graph\": graph_name,\n",
    "        \"predictions\": predictions_df,\n",
    "        \"metrics\": metrics,\n",
    "        \"embeddings\": embeddings\n",
    "    })\n",
    "\n",
    "for res in all_results:\n",
    "    graph_name = res[\"graph\"]\n",
    "    graph_metrics = res[\"metrics\"]\n",
    "    \n",
    "    acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "    f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "    f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "    recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "    auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "    \n",
    "    acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "    f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "    f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "    recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "    auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "\n",
    "    print(f\"\\nResults for: {graph_name}\")\n",
    "    print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "    print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "    print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "    print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "    print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43396d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/brca\")\n",
    "all_results = []\n",
    "\n",
    "for run_config in comparison_runs:\n",
    "    graph_name = run_config[\"name\"]\n",
    "    A_full = run_config[\"graph\"]\n",
    "    \n",
    "    current_output_dir = output_dir_base / graph_name\n",
    "    current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dpmon_params_base = {\n",
    "        \"adjacency_matrix\": A_full,\n",
    "        \"omics_list\": omics_brca,\n",
    "        \"phenotype_data\": target,\n",
    "        \"phenotype_col\": \"target\",\n",
    "        \"clinical_data\": clinical_for_model,\n",
    "        \"model\": 'SAGE',\n",
    "        \"tune\": True, \n",
    "        \"cv\": True,   \n",
    "        \"n_folds\": 5,\n",
    "        \"repeat_num\":5,\n",
    "        \"gpu\": True,\n",
    "        \"cuda\": 0,\n",
    "        \"seed\": SEED,\n",
    "        \"output_dir\": current_output_dir\n",
    "    }\n",
    "    \n",
    "    dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "    predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "\n",
    "    all_results.append({\n",
    "        \"graph\": graph_name,\n",
    "        \"predictions\": predictions_df,\n",
    "        \"metrics\": metrics,\n",
    "        \"embeddings\": embeddings\n",
    "    })\n",
    "\n",
    "for res in all_results:\n",
    "    graph_name = res[\"graph\"]\n",
    "    graph_metrics = res[\"metrics\"]\n",
    "    \n",
    "    acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "    f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "    f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "    recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "    auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "    \n",
    "    acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "    f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "    f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "    recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "    auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "\n",
    "    print(f\"\\nResults for: {graph_name}\")\n",
    "    print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "    print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "    print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "    print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "    print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb69e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/brca\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for run_config in comparison_runs:\n",
    "    graph_name = run_config[\"name\"]\n",
    "    A_full = run_config[\"graph\"]\n",
    "    \n",
    "    current_output_dir = output_dir_base / graph_name\n",
    "    current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dpmon_params_base = {\n",
    "        \"adjacency_matrix\": A_full,\n",
    "        \"omics_list\": omics_brca,\n",
    "        \"phenotype_data\": target,\n",
    "        \"phenotype_col\": \"target\",\n",
    "        \"clinical_data\": clinical_for_model,\n",
    "        \"model\": 'GCN',\n",
    "        \"tune\": True, \n",
    "        \"cv\": True,   \n",
    "        \"n_folds\": 5,\n",
    "        \"repeat_num\":5,\n",
    "        \"gpu\": True,\n",
    "        \"cuda\": 0,\n",
    "        \"seed\": SEED,\n",
    "        \"output_dir\": current_output_dir\n",
    "    }\n",
    "    \n",
    "    dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "    predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "\n",
    "    all_results.append({\n",
    "        \"graph\": graph_name,\n",
    "        \"predictions\": predictions_df,\n",
    "        \"metrics\": metrics,\n",
    "        \"embeddings\": embeddings\n",
    "    })\n",
    "\n",
    "for res in all_results:\n",
    "    graph_name = res[\"graph\"]\n",
    "    graph_metrics = res[\"metrics\"]\n",
    "    \n",
    "    acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "    f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "    f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "    recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "    auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "    \n",
    "    acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "    f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "    f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "    recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "    auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "\n",
    "    print(f\"\\nResults for: {graph_name}\")\n",
    "    print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "    print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "    print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "    print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "    print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.concat([dna_meth, rna, mirna, clinical_for_model], axis=1)\n",
    "y = target['vital_status']\n",
    "print(f\"Successfully created X matrix with shape: {X.shape}\")\n",
    "print(f\"Successfully created y vector with shape: {y.shape}\")\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(solver='lbfgs', max_iter=1000, penalty=None, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MLPClassifier(max_iter=500, early_stopping=True, n_iter_no_change=10, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBClassifier(eval_metric='logloss', tree_method='hist', max_bin=128, random_state=SEED))\n",
    "])\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "params_lr = {'model__penalty': ['l2'], 'model__C': loguniform(1e-4, 1e2)}\n",
    "\n",
    "params_mlp = {\n",
    "    'model__hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': loguniform(1e-5, 1e-1),\n",
    "    'model__learning_rate_init': loguniform(1e-4, 1e-2)\n",
    "}\n",
    "params_xgb = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': loguniform(0.01, 0.3),\n",
    "    'model__max_depth': randint(3, 7),\n",
    "    'model__subsample': [0.8, 1.0], \n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "params_rf = {\n",
    "    'model__n_estimators': randint(100, 300),\n",
    "    'model__max_depth': [10, 20, 30, None],\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 5),\n",
    "    'model__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "params_svm = {\n",
    "    'model__C': loguniform(1e-2, 1e3),\n",
    "    'model__kernel': ['rbf', 'linear'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "params_dt = {\n",
    "    'model__max_depth': randint(3, 15),\n",
    "    'model__min_samples_split': randint(2, 20),\n",
    "    'model__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "models_to_tune = {\n",
    "    \"LogisticRegression\": (pipe_lr, params_lr),\n",
    "    \"SVM\": (pipe_svm, params_svm),\n",
    "    \"MLP\": (pipe_mlp, params_mlp),\n",
    "    \"XGBoost\": (pipe_xgb, params_xgb),\n",
    "    \"RandomForest\": (pipe_rf, params_rf),\n",
    "    \"DecisionTree\": (pipe_dt, params_dt),\n",
    "}\n",
    "\n",
    "all_results = {\n",
    "    \"LogisticRegression\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "    \"MLP\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "    \"XGBoost\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "    \"RandomForest\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "    \"SVM\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "    \"DecisionTree\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": []},\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, (pipeline, param_dist) in models_to_tune.items():\n",
    "    print(f\"Evaluating model with nested CV: {model_name}\")\n",
    "    \n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=SEED)\n",
    "    \n",
    "    # inner folds are for finding the best hyperparameters\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        best_score_fold = -np.inf\n",
    "        best_params_fold = None\n",
    "        # May or may not want to set a seed here. A fix seed = same hyperparamters each fold.\n",
    "        # No seed = different hyperparameters each fold. This adds more randomness, and may yield better generalization.\n",
    "        param_sampler = list(ParameterSampler(param_dist, n_iter=20))\n",
    "        \n",
    "        for params in param_sampler:\n",
    "            inner_scores = []\n",
    "            \n",
    "            for inner_train_idx, inner_val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "                X_train_inner = X_train_outer.iloc[inner_train_idx]\n",
    "                X_val_inner = X_train_outer.iloc[inner_val_idx]\n",
    "                y_train_inner = y_train_outer.iloc[inner_train_idx]\n",
    "                y_val_inner = y_train_outer.iloc[inner_val_idx]\n",
    "                \n",
    "                inner_pipeline = clone(pipeline)\n",
    "                inner_pipeline.set_params(**params)\n",
    "                inner_pipeline.fit(X_train_inner, y_train_inner)\n",
    "                \n",
    "                y_val_pred = inner_pipeline.predict(X_val_inner)\n",
    "                score = f1_score(y_val_inner, y_val_pred, average='weighted', zero_division=0)\n",
    "                inner_scores.append(score)\n",
    "            \n",
    "            mean_score = np.mean(inner_scores)\n",
    "            if mean_score > best_score_fold:\n",
    "                best_score_fold = mean_score\n",
    "                best_params_fold = params\n",
    "        \n",
    "        print(f\"Outer fold {fold_idx}: best params (inner CV F1-W={best_score_fold:.4f})\")\n",
    "        print(f\"{best_params_fold}\")\n",
    "        \n",
    "        final_pipeline = clone(pipeline)\n",
    "        final_pipeline.set_params(**best_params_fold)\n",
    "        final_pipeline.fit(X_train_outer, y_train_outer)\n",
    "        \n",
    "        preds = final_pipeline.predict(X_test_outer)\n",
    "        \n",
    "        if hasattr(final_pipeline, \"predict_proba\"):\n",
    "            proba = final_pipeline.predict_proba(X_test_outer)\n",
    "        else:\n",
    "            proba = None\n",
    "        \n",
    "        acc = accuracy_score(y_test_outer, preds)\n",
    "        f1_w = f1_score(y_test_outer, preds, average='weighted', zero_division=0)\n",
    "        f1_m = f1_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        auc = np.nan\n",
    "        \n",
    "        if proba is not None:\n",
    "            try:\n",
    "                if len(np.unique(y)) == 2:\n",
    "                    auc = roc_auc_score(y_test_outer, proba[:, 1])\n",
    "                else:\n",
    "                    auc = roc_auc_score(y_test_outer, proba, multi_class='ovr', average='macro')\n",
    "                    y_test_bin = label_binarize(y_test_outer, classes=np.unique(y))\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "\n",
    "        print(f\"Fold {fold_idx} results: Acc={acc:.4f}, F1-W={f1_w:.4f}, \"\n",
    "              f\"F1-M={f1_m:.4f}, Recall={recall:.4f}, AUC={auc:.4f}\")\n",
    "        \n",
    "        all_results[model_name][\"acc\"].append(acc)\n",
    "        all_results[model_name][\"f1_w\"].append(f1_w)\n",
    "        all_results[model_name][\"f1_m\"].append(f1_m)\n",
    "        all_results[model_name][\"recall\"].append(recall)\n",
    "        all_results[model_name][\"auc\"].append(auc)\n",
    "\n",
    "print(\"\\nFINAL BASELINE RESULTS\\n\")\n",
    "for model_name, metrics in all_results.items():\n",
    "    avg_acc = np.mean(metrics[\"acc\"])\n",
    "    std_acc = np.std(metrics[\"acc\"])\n",
    "    avg_f1_w = np.mean(metrics[\"f1_w\"])\n",
    "    std_f1_w = np.std(metrics[\"f1_w\"])\n",
    "    avg_f1_m = np.mean(metrics[\"f1_m\"])\n",
    "    std_f1_m = np.std(metrics[\"f1_m\"])\n",
    "    avg_recall = np.mean(metrics[\"recall\"])\n",
    "    std_recall = np.std(metrics[\"recall\"])\n",
    "    avg_auc = np.nanmean(metrics[\"auc\"])\n",
    "    std_auc = np.nanstd(metrics[\"auc\"])\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    print(f\"F1 Weighted: {avg_f1_w:.4f} +/- {std_f1_w:.4f}\")\n",
    "    print(f\"F1 Macro: {avg_f1_m:.4f} +/- {std_f1_m:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
    "    print(f\"AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
