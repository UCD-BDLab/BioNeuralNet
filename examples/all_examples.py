"""
Usage Examples for BioNeuralNet Package

This script demonstrates how to utilize the BioNeuralNet package to integrate omics data
with neural network embeddings. It provides workflows using SmCCNet and WGCNA
for graph generation, followed by embedding generation and subject representation integration.
"""

import os
import pandas as pd

from bioneuralnet.graph_generation.smccnet import SmCCNet
from bioneuralnet.graph_generation.wgcna import WGCNA
from bioneuralnet.network_embedding.gnns import GNNEmbedding
from bioneuralnet.network_embedding.node2vec import Node2VecEmbedding
from bioneuralnet.subject_representation.subject_representation import SubjectRepresentationEmbedding


def run_smccnet_workflow():
    """
    Executes the SmCCNet-based workflow for generating enhanced omics data.

    This function performs the following steps:
        1. Instantiates the SmCCNet, GNNEmbedding, and SubjectRepresentationEmbedding components.
        2. Loads omics, phenotype, and clinical data.
        3. Generates an adjacency matrix using SmCCNet.
        4. Computes node features based on correlations.
        5. Generates embeddings using GNNEmbedding.
        6. Reduces embeddings using PCA.
        7. Integrates embeddings into omics data to produce enhanced omics data.
        8. Saves the enhanced omics data to the output directory.
    """
    try:
        # Step 1: Instantiate SmCCNet parameters
        smccnet_instance = SmCCNet(
            phenotype_file='input/phenotype_data.csv',
            omics_list=[
                'input/proteins.csv',
                'input/metabolites.csv'
            ],
            data_types=['protein', 'metabolite'],
            kfold=5,
            summarization='PCA',
            seed=732,
        )

        # Step 2: Load omics, phenotype, and clinical data
        omics_data = pd.read_csv('input/omics_data.csv', index_col=0)
        phenotype_data = pd.read_csv('input/phenotype_data.csv', index_col=0).squeeze()
        clinical_data = pd.read_csv('input/clinical_data.csv', index_col=0)

        # Step 3: Generate adjacency matrix using SmCCNet
        adjacency_matrix = smccnet_instance.run()

        # Save adjacency matrix
        # Output dir is automatically generated by SmCCNet
        adjacency_output_path = os.path.join(smccnet_instance.output_dir, 'adjacency_matrix.csv')
        adjacency_matrix.to_csv(adjacency_output_path)
        print(f"Adjacency matrix saved to {adjacency_output_path}")

        # Step 4: Compute node features based on correlations
        subject_rep = SubjectRepresentationEmbedding()
        node_phenotype_corr = subject_rep.compute_node_phenotype_correlation(omics_data, phenotype_data)
        node_clinical_corr = subject_rep.compute_node_clinical_correlation(omics_data, clinical_data)
        node_features = pd.concat([node_clinical_corr, node_phenotype_corr.rename('phenotype_corr')], axis=1)

        # Step 5: Generate embeddings using GNNEmbedding
        gnn_embedding = GNNEmbedding(
            input_dir='', 
            model_type='GCN',
            gnn_input_dim=node_features.shape[1],
            gnn_hidden_dim=64,
            gnn_layer_num=2,
            dropout=True,
        )
        embeddings_dict = gnn_embedding.run(graphs={'graph': adjacency_matrix}, node_features=node_features)
        embeddings_tensor = embeddings_dict['graph']
        embeddings_df = pd.DataFrame(embeddings_tensor.numpy(), index=node_features.index)

        # Step 6: Reduce embeddings using PCA
        node_embedding_values = subject_rep.reduce_embeddings(embeddings_df)

        # Step 7: Integrate embeddings into omics data
        enhanced_omics_data = subject_rep.run(
            adjacency_matrix=adjacency_matrix,
            omics_data=omics_data,
            phenotype_data=phenotype_data,
            clinical_data=clinical_data,
            embeddings=node_embedding_values
        )

        # Step 8: Save the enhanced omics data
        enhanced_omics_output_path = os.path.join(subject_rep.output_dir, 'enhanced_omics_data.csv')
        enhanced_omics_data.to_csv(enhanced_omics_output_path)
        print(f"Enhanced omics data saved to {enhanced_omics_output_path}")

    except FileNotFoundError as fnf_error:
        print(f"File not found error: {fnf_error}")
        raise fnf_error
    except Exception as e:
        print(f"An error occurred during the SmCCNet workflow: {e}")
        raise e


def run_wgcna_workflow():
    """
    Executes the WGCNA-based workflow for generating enhanced omics data.

    This function performs the following steps:
        1. Instantiates the WGCNA, GNNEmbedding, and SubjectRepresentationEmbedding components.
        2. Loads omics, phenotype, and clinical data.
        3. Generates an adjacency matrix using WGCNA.
        4. Computes node features based on correlations.
        5. Generates embeddings using GNNEmbedding.
        6. Reduces embeddings using PCA.
        7. Integrates embeddings into omics data to produce enhanced omics data.
        8. Saves the enhanced omics data to the output directory.
    """
    try:
        # Step 1: Instantiate WGCNA with direct parameters
        wgcna_instance = WGCNA(
            phenotype_file='input/phenotype_data.csv',
            omics_list=['input/omics_data.csv'],
            data_types=['gene'],  # Adjust based on your data
            soft_power=6,
            min_module_size=30,
            merge_cut_height=0.25,
        )

        # Step 2: Load omics, phenotype, and clinical data
        omics_data = pd.read_csv('input/omics_data.csv', index_col=0)
        phenotype_data = pd.read_csv('input/phenotype_data.csv', index_col=0).squeeze()
        clinical_data = pd.read_csv('input/clinical_data.csv', index_col=0)

        # Step 3: Generate adjacency matrix using WGCNA
        adjacency_matrix = wgcna_instance.run()

        # Save adjacency matrix
        adjacency_output_path = os.path.join(wgcna_instance.output_dir, 'adjacency_matrix.csv')
        adjacency_matrix.to_csv(adjacency_output_path)
        print(f"Adjacency matrix saved to {adjacency_output_path}")

        # Step 4: Compute node features based on correlations
        subject_rep = SubjectRepresentationEmbedding()
        node_phenotype_corr = subject_rep.compute_node_phenotype_correlation(omics_data, phenotype_data)
        node_clinical_corr = subject_rep.compute_node_clinical_correlation(omics_data, clinical_data)
        node_features = pd.concat([node_clinical_corr, node_phenotype_corr.rename('phenotype_corr')], axis=1)

        # Step 5: Generate embeddings using GNNEmbedding
        gnn_embedding = GNNEmbedding(
            input_dir='',  # Not used because we pass graphs directly
            model_type='GCN',
            gnn_input_dim=node_features.shape[1],
            gnn_hidden_dim=64,
            gnn_layer_num=2,
            dropout=True,
        )
        embeddings_dict = gnn_embedding.run(graphs={'graph': adjacency_matrix}, node_features=node_features)
        embeddings_tensor = embeddings_dict['graph']
        embeddings_df = pd.DataFrame(embeddings_tensor.numpy(), index=node_features.index)

        # Step 6: Reduce embeddings using PCA
        node_embedding_values = subject_rep.reduce_embeddings(embeddings_df)

        # Step 7: Integrate embeddings into omics data
        enhanced_omics_data = subject_rep.run(
            adjacency_matrix=adjacency_matrix,
            omics_data=omics_data,
            phenotype_data=phenotype_data,
            clinical_data=clinical_data,
            embeddings=node_embedding_values
        )

        # Step 8: Save the enhanced omics data
        enhanced_omics_output_path = os.path.join(subject_rep.output_dir, 'enhanced_omics_data.csv')
        enhanced_omics_data.to_csv(enhanced_omics_output_path)
        print(f"Enhanced omics data saved to {enhanced_omics_output_path}")

    except FileNotFoundError as fnf_error:
        print(f"File not found error: {fnf_error}")
        raise fnf_error
    except Exception as e:
        print(f"An error occurred during the WGCNA workflow: {e}")
        raise e


def run_smccnet_node2vec_workflow():
    """
    Executes the SmCCNet-based workflow using Node2Vec for generating enhanced omics data.

    This function performs the following steps:
        1. Instantiates the SmCCNet, Node2VecEmbedding, and SubjectRepresentationEmbedding components.
        2. Loads omics, phenotype, and clinical data.
        3. Generates an adjacency matrix using SmCCNet.
        4. Generates embeddings using Node2VecEmbedding.
        5. Reduces embeddings using PCA.
        6. Integrates embeddings into omics data to produce enhanced omics data.
        7. Saves the enhanced omics data to the output directory.
    """
    try:
        # Step 1: Instantiate SmCCNet with direct parameters
        smccnet_instance = SmCCNet(
            phenotype_file='input/phenotype_data.csv',
            omics_list=[
                'input/proteins.csv',
                'input/metabolites.csv'
            ],
            data_types=['protein', 'metabolite'],
            kfold=5,
            summarization='PCA',
            seed=732,
        )

        # Step 2: Load omics, phenotype, and clinical data
        omics_data = pd.read_csv('input/omics_data.csv', index_col=0)
        phenotype_data = pd.read_csv('input/phenotype_data.csv', index_col=0).squeeze()
        clinical_data = pd.read_csv('input/clinical_data.csv', index_col=0)

        # Step 3: Generate adjacency matrix using SmCCNet
        adjacency_matrix = smccnet_instance.run()

        # Save adjacency matrix
        adjacency_output_path = os.path.join(smccnet_instance.output_dir, 'adjacency_matrix.csv')
        adjacency_matrix.to_csv(adjacency_output_path)
        print(f"Adjacency matrix saved to {adjacency_output_path}")

        # Step 4: Generate embeddings using Node2VecEmbedding
        node2vec_embedding = Node2VecEmbedding(
            input_dir='', 
            embedding_dim=128,
            walk_length=80,
            num_walks=10,
            window_size=10,
            workers=4,
            seed=42,
        )
        embeddings_dict = node2vec_embedding.run(graphs={'graph': adjacency_matrix})
        embeddings_df = embeddings_dict['graph']
        embeddings_df.set_index('node', inplace=True)

        # Step 5: Reduce embeddings using PCA
        subject_rep = SubjectRepresentationEmbedding()
        node_embedding_values = subject_rep.reduce_embeddings(embeddings_df)

        # Step 6: Integrate embeddings into omics data
        enhanced_omics_data = subject_rep.run(
            adjacency_matrix=adjacency_matrix,
            omics_data=omics_data,
            phenotype_data=phenotype_data,
            clinical_data=clinical_data,
            embeddings=node_embedding_values
        )

        # Step 7: Save the enhanced omics data
        enhanced_omics_output_path = os.path.join(subject_rep.output_dir, 'enhanced_omics_data.csv')
        enhanced_omics_data.to_csv(enhanced_omics_output_path)
        print(f"Enhanced omics data saved to {enhanced_omics_output_path}")

    except FileNotFoundError as fnf_error:
        print(f"File not found error: {fnf_error}")
        raise fnf_error
    except Exception as e:
        print(f"An error occurred during the SmCCNet Node2Vec workflow: {e}")
        raise e


if __name__ == "__main__":
    """
    Main execution block to run example workflows.

    This block provides example workflows:
        1. SmCCNet-based workflow with GNN embeddings.
        2. WGCNA-based workflow with GNN embeddings.
        3. SmCCNet-based workflow with Node2Vec embeddings.
    """
    try:
        # Example 1
        print("Starting SmCCNet and GNNs Workflow...")
        run_smccnet_workflow()
        print("SmCCNet Workflow completed successfully.\n")

        # Example 2
        print("Starting WGCNA and GNNs Workflow...")
        run_wgcna_workflow()
        print("WGCNA Workflow completed successfully.\n")

        # Example 3
        print("Starting SmCCNet and Node2Vec Workflow...")
        run_smccnet_node2vec_workflow()
        print("SmCCNet Node2Vec Workflow completed successfully.\n")

    except Exception as e:
        print(f"An error occurred during the execution: {e}")
        raise e
