{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc820e6e",
   "metadata": {},
   "source": [
    "# TCGA-PAAD Analysis: *Overall Survival* classification\n",
    "\n",
    "- **Cohort**: Focuses on the **TCGA-PAAD** (Pancreatic Adenocarcinoma) dataset, a vital cohort for studying pancreatic cancer.\n",
    "\n",
    "- **Goal**: Perform survival prediction using a multi-omics profile.\n",
    "- **Prediction Target**: Predict **Overall Survival (OS)** based on the patient's omics data (RNA, Methylation, CNV, and clinical features).\n",
    "\n",
    "**Data Sources:**\n",
    "- Omics Data and Target: [https://xenabrowser.net/datapages/](https://xenabrowser.net/datapages/)\n",
    "- Clinical Data: [Broad Institute FireHose](http://firebrowse.org/?cohort=PAAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "root = Path(\"/home/vicente/Github/BioNeuralNet/PAAN\")\n",
    "\n",
    "cnv_gistic_raw = pd.read_csv(root/\"Gistic2_CopyNumber_Gistic2_all_thresholded_by_genes.txt\", sep=\"\\t\",index_col=0,low_memory=False)                            \n",
    "rna_raw = pd.read_csv(root / \"HiSeqV2.txt\", sep=\"\\t\",index_col=0,low_memory=False)\n",
    "meth_raw = pd.read_csv(root/\"HumanMethylation450.txt\", sep='\\t',index_col=0,low_memory=False)\n",
    "clinical_raw = pd.read_csv(root / \"PAAD.clin.merged.picked.txt\",sep=\"\\t\", index_col=0, low_memory=False)\n",
    "target = pd.read_csv(root / \"survival_PAAD_survival.txt\", sep=\"\\t\", index_col=0, low_memory=False)\n",
    "probe_map_meth = pd.read_csv( root / \"probeMap_illuminaMethyl450_hg19_GPL16304_TCGAlegacy.txt\", sep=\"\\t\", index_col=0, low_memory=False)\n",
    "\n",
    "# display all shapes and first few rows of each dataset\n",
    "display(cnv_gistic_raw.iloc[:5,:5])\n",
    "display(cnv_gistic_raw.shape)\n",
    "\n",
    "display(rna_raw.iloc[:5,:5])\n",
    "display(rna_raw.shape)\n",
    "\n",
    "display(meth_raw.iloc[:5,:5])\n",
    "display(meth_raw.shape)\n",
    "display(probe_map_meth.iloc[:5,:5])\n",
    "display(probe_map_meth.shape)\n",
    "\n",
    "display(clinical_raw.iloc[:5,:5])\n",
    "display(clinical_raw.shape)\n",
    "\n",
    "display(target.iloc[:5,:5])\n",
    "display(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "cnv_gistic_processed = cnv_gistic_raw.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# collapse GISTIC to -1 / 0 / +1 per gene\n",
    "cnv_signed = cnv_gistic_processed.copy()\n",
    "cnv_signed[cnv_signed > 0] = 1\n",
    "cnv_signed[cnv_signed < 0] = -1\n",
    "\n",
    "cnv_signed_T = cnv_signed.T \n",
    "rna_numeric = rna_raw.apply(pd.to_numeric, errors=\"coerce\")\n",
    "rna_T = rna_numeric.T\n",
    "\n",
    "# make numeric (beta values)\n",
    "meth_numeric = meth_raw.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# build gene map from probe_map_meth\n",
    "gene_map = probe_map_meth[['gene']].copy()\n",
    "gene_map = gene_map.dropna(subset=['gene'])\n",
    "gene_map = gene_map[gene_map['gene'] != '.']\n",
    "\n",
    "gene_map['gene'] = gene_map['gene'].str.split(',')\n",
    "gene_map_exploded = gene_map.explode('gene')\n",
    "\n",
    "meth_with_gene = meth_numeric.join(gene_map_exploded['gene'], how='inner')\n",
    "\n",
    "data_cols = meth_with_gene.columns.drop('gene')\n",
    "meth_gene_beta = (\n",
    "    meth_with_gene\n",
    "    .groupby('gene')[data_cols]\n",
    "    .mean()\n",
    "    .T\n",
    ")\n",
    "\n",
    "meth_gene_m = bnn.utils.beta_to_m(meth_gene_beta, eps=1e-8)\n",
    "\n",
    "clinical = clinical_raw.copy()\n",
    "clinical = clinical.T\n",
    "clinical.index = clinical.index.str.upper().str.slice(0, 12)\n",
    "clinical.index.name = \"Patient_ID\"\n",
    "clinical = clinical[~clinical.index.duplicated(keep='first')]\n",
    "clinical = clinical.drop(columns=[\"Hybridization REF\", \"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "outcomes = target.copy()\n",
    "outcomes = outcomes.set_index('_PATIENT')\n",
    "outcomes.index = outcomes.index.str.upper().str.slice(0, 12)\n",
    "outcomes.index.name = \"Patient_ID\"\n",
    "outcomes = outcomes[~outcomes.index.duplicated(keep='first')]\n",
    "\n",
    "cnv_signed_T.index = cnv_signed_T.index.str.upper().str.slice(0, 12)\n",
    "rna_T.index = rna_T.index.str.upper().str.slice(0, 12)\n",
    "meth_gene_m.index  = meth_gene_m.index.str.upper().str.slice(0, 12)\n",
    "\n",
    "cnv_signed_T = cnv_signed_T.groupby(cnv_signed_T.index).mean()\n",
    "rna_T = rna_T.groupby(rna_T.index).mean()\n",
    "meth_gene_m  = meth_gene_m.groupby(meth_gene_m.index).mean()\n",
    "\n",
    "common_patients = sorted(\n",
    "    set(cnv_signed_T.index)\n",
    "    & set(rna_T.index)\n",
    "    & set(meth_gene_m.index)\n",
    "    & set(outcomes.index)\n",
    ")\n",
    "X_cnv = cnv_signed_T.loc[common_patients]\n",
    "X_rna = rna_T.loc[common_patients]\n",
    "X_meth = meth_gene_m.loc[common_patients]\n",
    "Y_labels = outcomes.loc[common_patients, \"OS\"]\n",
    "clinical = clinical.loc[common_patients]\n",
    "\n",
    "def clean_cols(df, prefix):\n",
    "    cols = df.columns\n",
    "    cols = cols.str.replace(r\"\\?\", \"unknown_\", regex=True)\n",
    "    cols = cols.str.replace(r\"\\|\", \"_\", regex=True)\n",
    "    cols = cols.str.replace(\"-\", \"_\", regex=False)\n",
    "    cols = cols.str.replace(r\"_+\", \"_\", regex=True)\n",
    "    cols = cols.str.strip(\"_\")\n",
    "    df.columns = cols\n",
    "    return df.add_prefix(prefix)\n",
    "\n",
    "X_cnv = clean_cols(X_cnv, \"cnv_\")\n",
    "X_rna = clean_cols(X_rna, \"rna_\")\n",
    "X_meth = clean_cols(X_meth, \"meth_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81713f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_cnv.iloc[:5,:5])\n",
    "display(X_cnv.shape)\n",
    "\n",
    "display(X_rna.iloc[:5,:5])\n",
    "display(X_rna.shape)\n",
    "\n",
    "display(X_meth.iloc[:5,:5])\n",
    "display(X_meth.shape)\n",
    "\n",
    "display(clinical.iloc[:5,:5])\n",
    "display(clinical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767b027",
   "metadata": {},
   "source": [
    "## Feature Selection Methodology\n",
    "\n",
    "### Supported Methods and Interpretation\n",
    "\n",
    "**BioNeuralNet** provides three techniques for feature selection, allowing for different views of the data's statistical profile:\n",
    "\n",
    "- **Variance Thresholding:** Identifies features with the **highest overall variance** across all samples.\n",
    "\n",
    "- **ANOVA F-test:** Pinpoints features that best **distinguish between the target classes** (e.g., Alive vs. Deceased).\n",
    "\n",
    "- **Random Forest Importance:** Assesses **feature utility** based on its contribution to a predictive non-linear model.\n",
    "\n",
    "### PAAD Cohort Selection Strategy\n",
    "\n",
    "A dimensionality reduction step was essential for managing the high-feature-count omics data:\n",
    "\n",
    "- **High-Feature Datasets:** DNA Methylation (34,013), RNA (20,530), CNV Amplification (24,776), and CNV Deletion (24,776) all required significant feature reduction.\n",
    "\n",
    "- **Filtering Process:** As an example strategy, the **top 6,000 features** could be extracted from each high-feature omics dataset using all three methods.\n",
    "\n",
    "- **Final Set:** A consensus set could be built for each omics type by finding the intersection of features selected by the ANOVA F-test and Random Forest Importance, ensuring both statistical relevance and model-based utility.\n",
    "\n",
    "- **Low-Feature Datasets:** The **Clinical** data (19 features) was passed through **without selection**, as its feature count was already manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3941c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "print(f\"METH before: {X_meth.shape}\")\n",
    "X_meth = bnn.impute_omics_knn(X_meth, n_neighbors=5)\n",
    "print(f\"METH after: {X_meth.shape}\\n\")\n",
    "\n",
    "print(f\"RNA before: {X_rna.shape}\")\n",
    "X_rna = bnn.impute_omics_knn(X_rna, n_neighbors=5)\n",
    "print(f\"RNA after: {X_rna.shape}\\n\")\n",
    "\n",
    "print(f\"CNV before: {X_cnv.shape}\")\n",
    "X_cnv = bnn.impute_omics_knn(X_cnv, n_neighbors=5)\n",
    "print(f\"CNV after: {X_cnv.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "meth_highvar = bnn.utils.select_top_k_variance(X_meth, k=6000)\n",
    "meth_af = bnn.utils.top_anova_f_features(X_meth, Y_labels, max_features=6000)\n",
    "meth_rf = bnn.utils.select_top_randomforest(X_meth, Y_labels, top_k=6000)\n",
    "\n",
    "rna_highvar = bnn.utils.select_top_k_variance(X_rna, k=6000)\n",
    "rna_af = bnn.utils.top_anova_f_features(X_rna, Y_labels, max_features=6000)\n",
    "rna_rf = bnn.utils.select_top_randomforest(X_rna, Y_labels, top_k=6000)\n",
    "\n",
    "cnv_highvar = bnn.utils.select_top_k_variance(X_cnv, k=6000)\n",
    "cnv_af = bnn.utils.top_anova_f_features(X_cnv, Y_labels, max_features=6000)\n",
    "cnv_rf = bnn.utils.select_top_randomforest(X_cnv, Y_labels, top_k=6000)\n",
    "\n",
    "meth_var_set = set(meth_highvar.columns)\n",
    "meth_anova_set = set(meth_af.columns)\n",
    "meth_rf_set = set(meth_rf.columns)\n",
    "\n",
    "rna_var_set = set(rna_highvar.columns)\n",
    "rna_anova_set = set(rna_af.columns)\n",
    "rna_rf_set = set(rna_rf.columns)\n",
    "\n",
    "cnv_var_set = set(cnv_highvar.columns)\n",
    "cnv_anova_set = set(cnv_af.columns)\n",
    "cnv_rf_set = set(cnv_rf.columns)\n",
    "\n",
    "meth_inter1 = list(meth_anova_set & meth_var_set)\n",
    "meth_inter2 = list(meth_rf_set & meth_var_set)\n",
    "meth_inter3 = list(meth_anova_set & meth_rf_set)\n",
    "meth_all_three = list(meth_anova_set & meth_var_set & meth_rf_set)\n",
    "\n",
    "rna_inter1 = list(rna_anova_set & rna_var_set)\n",
    "rna_inter2 = list(rna_rf_set & rna_var_set)\n",
    "rna_inter3 = list(rna_anova_set & rna_rf_set)\n",
    "rna_all_three = list(rna_anova_set & rna_var_set & rna_rf_set)\n",
    "\n",
    "cnv_inter1 = list(cnv_anova_set & cnv_var_set)\n",
    "cnv_inter2 = list(cnv_rf_set & cnv_var_set)\n",
    "cnv_inter3 = list(cnv_anova_set & cnv_rf_set)\n",
    "cnv_all_three = list(cnv_anova_set & cnv_var_set & cnv_rf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FROM THE 6000 Methylation feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(meth_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(meth_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(meth_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(meth_all_three)} features\")\n",
    "\n",
    "print(\"\\nFROM THE 6000 RNA feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(rna_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(rna_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(rna_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(rna_all_three)} features\")\n",
    "\n",
    "print(\"\\nFROM THE 6000 CNV feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(cnv_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(cnv_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(cnv_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(cnv_all_three)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61f83a",
   "metadata": {},
   "source": [
    "## Feature Selection Summary: ANOVA-RF Intersection\n",
    "\n",
    "The final set of features was determined by the **intersection** of those highlighted by the **ANOVA F-test** and **Random Forest Importance**. This methodology provides a balanced filter, capturing features with both high class-separability (ANOVA) and significant predictive value in a non-linear model (Random Forest). The resulting feature pool is considered highly relevant for the subsequent modeling tasks.\n",
    "\n",
    "### Feature Overlap Results\n",
    "\n",
    "The table below quantifies the shared features identified by the different selection techniques for each omics type.\n",
    "\n",
    "| Omics Data Type | ANOVA-F & Variance | RF & Variance | ANOVA-F & Random Forest (Selected) | All Three Agree |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **DNA Methylation** | 1,410 features | 1,076 features | **1,152 features** | 280 features |\n",
    "| **RNA** | 1,910 features | 1,815 features | **1,910 features** | 589 features |\n",
    "| **CNV** | 1,884 features | 1,516 features | **1,035 features** | 477 features |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a83aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset each omics dataframe using the selected feature lists\n",
    "X_meth_selected = X_meth[meth_inter3]\n",
    "X_rna_selected = X_rna[rna_inter3]\n",
    "X_cnv_selected = X_cnv[cnv_inter3]\n",
    "\n",
    "print(\"\\nFinal Shapes for Modeling\")\n",
    "print(f\"Methylation (X_meth_selected): {X_meth_selected.shape}\")\n",
    "print(f\"RNA-Seq (X_rna_selected): {X_rna_selected.shape}\")\n",
    "print(f\"CNV (X_cnv_selected): {X_cnv_selected.shape}\")\n",
    "print(f\"Clinical (clinical_selected): {clinical.shape}\")\n",
    "print(f\"Labels (Y_labels): {Y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706f2e3",
   "metadata": {},
   "source": [
    "## Data Availability\n",
    "\n",
    "To facilitate rapid experimentation and reproduction of our results, the fully processed and feature-selected dataset used in this analysis has been made available directly within the package.\n",
    "\n",
    "Users can load this dataset, bypassing all preceding data acquisition, preprocessing, and feature selection steps. This allows users to proceed immediately from this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ce715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training puroses we will do variance selection to reduce the number of features\n",
    "import bioneuralnet as bnn\n",
    "\n",
    "tgca_paad = bnn.datasets.DatasetLoader(\"paad\")\n",
    "display(tgca_paad.shape)\n",
    "\n",
    "# The dataset is returned as a dictionary. We extract each file independetly based on the name (Key).\n",
    "cnv = tgca_paad[\"cnv\"]\n",
    "clinical = tgca_paad[\"clinical\"]\n",
    "target = tgca_paad[\"target\"]\n",
    "dna_meth = tgca_paad[\"meth\"]\n",
    "rna = tgca_paad[\"rna\"]\n",
    "\n",
    "display(cnv.iloc[:3,:5])\n",
    "display(dna_meth.iloc[:3,:5])\n",
    "display(rna.iloc[:3,:5])\n",
    "display(clinical.iloc[:3,:5])\n",
    "display(target.iloc[:2,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance selection\n",
    "cnv = bnn.utils.select_top_k_variance(cnv, k=500)\n",
    "dna_meth = bnn.utils.select_top_k_variance(dna_meth, k=500)\n",
    "rna = bnn.utils.select_top_k_variance(rna, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import preprocess_clinical\n",
    "\n",
    "dataleak_columns = [\n",
    "        \"vital_status\",\n",
    "        \"days_to_death\",\n",
    "        \"days_to_last_followup\",\n",
    "        \"date_of_initial_pathologic_diagnosis\",\n",
    "    ]\n",
    "\n",
    "clinical_for_model = preprocess_clinical(\n",
    "    clinical, \n",
    "    top_k=10, \n",
    "    scale=False, \n",
    "    ignore_columns=dataleak_columns,\n",
    "    nan_threshold=0.6)\n",
    "\n",
    "display(clinical_for_model.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecd4a7",
   "metadata": {},
   "source": [
    "## Reproducibility and Seeding\n",
    "\n",
    "To ensure our experimental results are fully reproducible, a single global seed is set at the beginning of the analysis.\n",
    "\n",
    "This utility function propagates the seed to all sources of randomness, including `random`, `numpy`, and `torch` (for both CPU and GPU). Critically, it also configures the PyTorch cuDNN backend to use deterministic algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8428d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 1883\n",
    "bnn.utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ce1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import find_optimal_graph\n",
    "\n",
    "omics_paad = pd.concat([cnv, dna_meth, rna], axis=1)\n",
    "\n",
    "optimal_graph, best_params, results_df = find_optimal_graph(\n",
    "    omics_data=omics_paad,\n",
    "    y_labels=target,\n",
    "    methods=['threshold', 'correlation','similarity','gaussian'],\n",
    "    seed=SEED,\n",
    "    verbose=False,\n",
    "    trials=30,\n",
    "    omics_list=[cnv, dna_meth, rna],\n",
    "    centrality_mode=\"eigenvector\",\n",
    ")\n",
    "display(optimal_graph.iloc[:5,:5])\n",
    "display(best_params)\n",
    "\n",
    "results_df.sort_values(\"score\", ascending=False, inplace=True)\n",
    "display(results_df)\n",
    "## {'k': 20,'metric': 'cosine','mutual': False, 'linkage_mode': 'eigen_corr', 'epsilon': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph analysis: The optimal gaph uses a proxy to evaluate its properties, but for the final output\n",
    "# the graph is built without the target variable. The search only helps to find the best graph parameters..\n",
    "from bioneuralnet.utils import graph_analysis\n",
    "\n",
    "graph_analysis(optimal_graph, graph_name=\"Optimal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/paad\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"Gat_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_paad,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GAT',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/paad\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"Gcn_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_paad,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GCN',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GIN_FINAL/paad\")\n",
    "\n",
    "\n",
    "current_output_dir = output_dir_base / \"gin_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_paad,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GIN',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96dcd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/paad\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"sage_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_paad,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'SAGE',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.concat([dna_meth, rna, cnv, clinical_for_model], axis=1)\n",
    "y = target['target']\n",
    "print(f\"Successfully created X matrix with shape: {X.shape}\")\n",
    "print(f\"Successfully created y vector with shape: {y.shape}\")\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(solver='lbfgs', max_iter=1000, penalty=None, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MLPClassifier(max_iter=500, early_stopping=True, n_iter_no_change=10, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBClassifier(eval_metric='logloss', tree_method='hist', max_bin=128, random_state=SEED))\n",
    "])\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "params_lr = {'model__penalty': ['l2'], 'model__C': loguniform(1e-4, 1e2)}\n",
    "\n",
    "params_mlp = {\n",
    "    'model__hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': loguniform(1e-5, 1e-1),\n",
    "    'model__learning_rate_init': loguniform(1e-4, 1e-2)\n",
    "}\n",
    "params_xgb = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': loguniform(0.01, 0.3),\n",
    "    'model__max_depth': randint(3, 7),\n",
    "    'model__subsample': [0.8, 1.0], \n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "params_rf = {\n",
    "    'model__n_estimators': randint(100, 300),\n",
    "    'model__max_depth': [10, 20, 30, None],\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 5),\n",
    "    'model__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "params_svm = {\n",
    "    'model__C': loguniform(1e-2, 1e3),\n",
    "    'model__kernel': ['rbf', 'linear'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "params_dt = {\n",
    "    'model__max_depth': randint(3, 15),\n",
    "    'model__min_samples_split': randint(2, 20),\n",
    "    'model__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "models_to_tune = {\n",
    "    \"LogisticRegression\": (pipe_lr, params_lr),\n",
    "    \"SVM\": (pipe_svm, params_svm),\n",
    "    \"MLP\": (pipe_mlp, params_mlp),\n",
    "    \"XGBoost\": (pipe_xgb, params_xgb),\n",
    "    \"RandomForest\": (pipe_rf, params_rf),\n",
    "    \"DecisionTree\": (pipe_dt, params_dt),\n",
    "}\n",
    "\n",
    "all_results = {\n",
    "    \"LogisticRegression\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"MLP\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"XGBoost\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"RandomForest\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"SVM\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"DecisionTree\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, (pipeline, param_dist) in models_to_tune.items():\n",
    "    print(f\"Evaluating model with nested CV: {model_name}\")\n",
    "    \n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=SEED)\n",
    "    \n",
    "    # inner folds are for finding the best hyperparameters\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        \n",
    "        best_score_fold = -np.inf\n",
    "        best_params_fold = None\n",
    "        # May or may not want to set a seed here. A fix seed = same hyperparamters each fold.\n",
    "        # No seed = different hyperparameters each fold. This adds more randomness, and may yield better generalization.\n",
    "        param_sampler = list(ParameterSampler(param_dist, n_iter=20))\n",
    "        \n",
    "        for params in param_sampler:\n",
    "            inner_scores = []\n",
    "            \n",
    "            for inner_train_idx, inner_val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "                X_train_inner = X_train_outer.iloc[inner_train_idx]\n",
    "                X_val_inner = X_train_outer.iloc[inner_val_idx]\n",
    "                y_train_inner = y_train_outer.iloc[inner_train_idx]\n",
    "                y_val_inner = y_train_outer.iloc[inner_val_idx]\n",
    "                \n",
    "                inner_pipeline = clone(pipeline)\n",
    "                inner_pipeline.set_params(**params)\n",
    "                inner_pipeline.fit(X_train_inner, y_train_inner)\n",
    "                \n",
    "                y_val_pred = inner_pipeline.predict(X_val_inner)\n",
    "                score = f1_score(y_val_inner, y_val_pred, average='weighted', zero_division=0)\n",
    "                inner_scores.append(score)\n",
    "            \n",
    "            mean_score = np.mean(inner_scores)\n",
    "            if mean_score > best_score_fold:\n",
    "                best_score_fold = mean_score\n",
    "                best_params_fold = params\n",
    "        \n",
    "        print(f\"Outer fold {fold_idx}: best params (inner CV F1-W={best_score_fold:.4f})\")\n",
    "        print(f\"{best_params_fold}\")\n",
    "        \n",
    "        final_pipeline = clone(pipeline)\n",
    "        final_pipeline.set_params(**best_params_fold)\n",
    "        final_pipeline.fit(X_train_outer, y_train_outer)\n",
    "        \n",
    "        preds = final_pipeline.predict(X_test_outer)\n",
    "        \n",
    "        if hasattr(final_pipeline, \"predict_proba\"):\n",
    "            proba = final_pipeline.predict_proba(X_test_outer)\n",
    "        else:\n",
    "            proba = None\n",
    "        \n",
    "        acc = accuracy_score(y_test_outer, preds)\n",
    "        f1_w = f1_score(y_test_outer, preds, average='weighted', zero_division=0)\n",
    "        f1_m = f1_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        auc = np.nan\n",
    "        aupr = np.nan\n",
    "        \n",
    "        if proba is not None:\n",
    "            try:\n",
    "                if len(np.unique(y)) == 2:\n",
    "                    auc = roc_auc_score(y_test_outer, proba[:, 1])\n",
    "                    aupr = average_precision_score(y_test_outer, proba[:, 1])\n",
    "                else:\n",
    "                    auc = roc_auc_score(y_test_outer, proba, multi_class='ovr', average='macro')\n",
    "                    y_test_bin = label_binarize(y_test_outer, classes=np.unique(y))\n",
    "                    aupr = average_precision_score(y_test_bin, proba, average='weighted')\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "                aupr = np.nan\n",
    "\n",
    "        print(f\"Fold {fold_idx} results: Acc={acc:.4f}, F1-W={f1_w:.4f}, \"\n",
    "              f\"F1-M={f1_m:.4f}, Recall={recall:.4f}, AUC={auc:.4f}, AUPR={aupr:.4f}\")\n",
    "        \n",
    "        all_results[model_name][\"acc\"].append(acc)\n",
    "        all_results[model_name][\"f1_w\"].append(f1_w)\n",
    "        all_results[model_name][\"f1_m\"].append(f1_m)\n",
    "        all_results[model_name][\"recall\"].append(recall)\n",
    "        all_results[model_name][\"auc\"].append(auc)\n",
    "        all_results[model_name][\"aupr\"].append(aupr)\n",
    "\n",
    "print(\"\\nFINAL BASELINE RESULTS\\n\")\n",
    "for model_name, metrics in all_results.items():\n",
    "    avg_acc = np.mean(metrics[\"acc\"])\n",
    "    std_acc = np.std(metrics[\"acc\"])\n",
    "    avg_f1_w = np.mean(metrics[\"f1_w\"])\n",
    "    std_f1_w = np.std(metrics[\"f1_w\"])\n",
    "    avg_f1_m = np.mean(metrics[\"f1_m\"])\n",
    "    std_f1_m = np.std(metrics[\"f1_m\"])\n",
    "    avg_recall = np.mean(metrics[\"recall\"])\n",
    "    std_recall = np.std(metrics[\"recall\"])\n",
    "    avg_auc = np.nanmean(metrics[\"auc\"])\n",
    "    std_auc = np.nanstd(metrics[\"auc\"])\n",
    "    avg_aupr = np.nanmean(metrics[\"aupr\"])\n",
    "    std_aupr = np.nanstd(metrics[\"aupr\"])\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    print(f\"F1 Weighted: {avg_f1_w:.4f} +/- {std_f1_w:.4f}\")\n",
    "    print(f\"F1 Macro: {avg_f1_m:.4f} +/- {std_f1_m:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
    "    print(f\"AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "    print(f\"AUPR: {avg_aupr:.4f} +/- {std_aupr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "# plotting function, the values below were enter manually\n",
    "\n",
    "baseline_data = {\n",
    "    \"Accuracy\": {\n",
    "        \"GIN\": (0.7005, 0.0583),\n",
    "        \"GraphSAGE\": (0.7005, 0.0934),\n",
    "        \"GAT\": (0.6894, 0.0646),\n",
    "        \"GCN\": (0.6608, 0.0469),\n",
    "        \"LogReg\": (0.7062, 0.0560),\n",
    "        \"SVM\": (0.6778, 0.0620),\n",
    "        \"XGBoost\": (0.6779, 0.0721),\n",
    "        \"MLP\": (0.6710, 0.0667),\n",
    "        \"Random Forest\": (0.6665, 0.0830),\n",
    "        \"Decision Tree\": (0.5715, 0.0654),\n",
    "    },\n",
    "    \"F1 Weighted\": {\n",
    "        \"GIN\": (0.6973, 0.0601),\n",
    "        \"GraphSAGE\": (0.6925, 0.0984),\n",
    "        \"GAT\": (0.6774, 0.0701),\n",
    "        \"GCN\": (0.6515, 0.0487),\n",
    "        \"LogReg\": (0.7025, 0.0586),\n",
    "        \"SVM\": (0.6740, 0.0630),\n",
    "        \"XGBoost\": (0.6715, 0.0740),\n",
    "        \"MLP\": (0.6678, 0.0690),\n",
    "        \"Random Forest\": (0.6592, 0.0870),\n",
    "        \"Decision Tree\": (0.5663, 0.0659),\n",
    "    },\n",
    "    \"F1 Macro\": {\n",
    "        \"GIN\": (0.6966, 0.0602),\n",
    "        \"GraphSAGE\": (0.6924, 0.0911),\n",
    "        \"GAT\": (0.6762, 0.0629),\n",
    "        \"GCN\": (0.6505, 0.0435),\n",
    "        \"LogReg\": (0.7008, 0.0597),\n",
    "        \"SVM\": (0.6725, 0.0637),\n",
    "        \"XGBoost\": (0.6693, 0.0751),\n",
    "        \"MLP\": (0.6662, 0.0697),\n",
    "        \"Random Forest\": (0.6568, 0.0883),\n",
    "        \"Decision Tree\": (0.5648, 0.0668),\n",
    "    },\n",
    "}\n",
    "\n",
    "baseline_data_cont = {\n",
    "    \"Recall\": {\n",
    "        \"GIN\": (0.7002, 0.0589),\n",
    "        \"GraphSAGE\": (0.7032, 0.0734),\n",
    "        \"GAT\": (0.6883, 0.0553),\n",
    "        \"GCN\": (0.6607, 0.0427),\n",
    "        \"LogReg\": (0.7032, 0.0585),\n",
    "        \"SVM\": (0.6755, 0.0631),\n",
    "        \"XGBoost\": (0.6737, 0.0736),\n",
    "        \"MLP\": (0.6686, 0.0682),\n",
    "        \"Random Forest\": (0.6620, 0.0846),\n",
    "        \"Decision Tree\": (0.5700, 0.0671),\n",
    "    },\n",
    "    \"AUC\": {\n",
    "        \"GIN\": (0.7471, 0.0573),\n",
    "        \"GraphSAGE\": (0.7482, 0.0772),\n",
    "        \"GAT\": (0.7418, 0.0784),\n",
    "        \"GCN\": (0.7390, 0.0779),\n",
    "        \"LogReg\": (0.7905, 0.0590),\n",
    "        \"SVM\": (0.7602, 0.0604),\n",
    "        \"XGBoost\": (0.7454, 0.0852),\n",
    "        \"MLP\": (0.7363, 0.0720),\n",
    "        \"Random Forest\": (0.7509, 0.0813),\n",
    "        \"Decision Tree\": (0.5802, 0.0747),\n",
    "    },\n",
    "    \"AUPR\": {\n",
    "        \"GIN\": (0.7634, 0.0743),\n",
    "        \"GraphSAGE\": (0.7812, 0.0722),\n",
    "        \"GAT\": (0.7570, 0.0872),\n",
    "        \"GCN\": (0.7661, 0.0739),\n",
    "        \"LogReg\": (0.8042, 0.0689),\n",
    "        \"SVM\": (0.7824, 0.0574),\n",
    "        \"XGBoost\": (0.7624, 0.0836),\n",
    "        \"MLP\": (0.7533, 0.0824),\n",
    "        \"Random Forest\": (0.7770, 0.0734),\n",
    "        \"Decision Tree\": (0.5869, 0.0559),\n",
    "    },\n",
    "}\n",
    "\n",
    "bnn.metrics.plot_multiple_metrics(\n",
    "    baseline_data,\n",
    "    title_map={\n",
    "        \"Accuracy\": \"GNNs vs Baselines: Accuracy\",\n",
    "        \"F1 Weighted\": \"GNNs vs Baselines: F1 Weighted\",\n",
    "        \"F1 Macro\": \"GNNs vs Baselines: F1 Macro\",\n",
    "    }\n",
    ")\n",
    "\n",
    "bnn.metrics.plot_multiple_metrics(\n",
    "    baseline_data_cont,\n",
    "    title_map={\n",
    "        \"Recall\": \"GNNs vs Baselines: Recall\",\n",
    "        \"AUC\": \"GNNs vs Baselines: AUC\",\n",
    "        \"AUPR\": \"GNNs vs Baselines: AUPR\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
