{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42de981",
   "metadata": {},
   "source": [
    "# TCGA-LGG Analysis: *Vital Status* classification\n",
    "\n",
    "- **Cohort**: Focuses on the TCGA-LGG dataset for Lower-Grade Glioma (LGG).\n",
    "- **Goal**: Classification\n",
    "- **Prediction Target**: Predict `Vital Status` based on their omics profiles.\n",
    "\n",
    "**Data Source:** [Broad Institute FireHose](http://firebrowse.org/?cohort=LGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "root = Path(\"/home/vicente/Github/BioNeuralNet/LGG\")\n",
    "\n",
    "mirna_raw = pd.read_csv(root/\"LGG.miRseq_RPKM_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)                            \n",
    "rna_raw = pd.read_csv(root / \"LGG.uncv2.mRNAseq_RSEM_normalized_log2.txt\", sep=\"\\t\",index_col=0,low_memory=False)\n",
    "meth_raw = pd.read_csv(root/\"LGG.meth.by_mean.data.txt\", sep='\\t',index_col=0,low_memory=False)\n",
    "clinical_raw = pd.read_csv(root / \"LGG.clin.merged.picked.txt\",sep=\"\\t\", index_col=0, low_memory=False)\n",
    "\n",
    "# display shapes and first few rows-columns of each file\n",
    "display(mirna_raw.iloc[:3,:5])\n",
    "display(mirna_raw.shape)\n",
    "\n",
    "display(rna_raw.iloc[:3,:5])\n",
    "display(meth_raw.shape)\n",
    "\n",
    "display(meth_raw.iloc[:3,:5])\n",
    "display(meth_raw.shape)\n",
    "\n",
    "display(clinical_raw.iloc[:3,:5])\n",
    "display(clinical_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacccaf",
   "metadata": {},
   "source": [
    "## Data Processing Summary\n",
    "\n",
    "1. **Transpose Data:** All raw data (miRNA, RNA, etc.) is flipped so rows represent patients and columns represent features.\n",
    "2. **Standardize Patient IDs:** Patient IDs in all tables are cleaned to the 12-character TCGA format (e.g., `TCGA-AB-1234`) for matching.\n",
    "3. **Handle Duplicates:** Duplicate patient rows are averaged in the omics data. The first entry is kept for duplicate patients in the clinical data.\n",
    "4. **Find Common Patients:** The script identifies the list of patients that exist in *all* datasets.\n",
    "5. **Subset Data:** All data tables are filtered down to *only* this common list of patients, ensuring alignment.\n",
    "6. **Extract Target:** The `vital_status` column is pulled from the processed clinical data to be used as the prediction target (y-variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna = mirna_raw.T\n",
    "rna = rna_raw.T\n",
    "meth = meth_raw.T\n",
    "clinical = clinical_raw.T\n",
    "\n",
    "print(f\"miRNA (samples, features): {mirna.shape}\")\n",
    "print(f\"RNA (samples, features): {rna.shape}\")\n",
    "print(f\"Methylation (samples, features): {meth.shape}\")\n",
    "print(f\"Clinical (samples, features): {clinical.shape}\")\n",
    "\n",
    "def trim_barcode(idx):\n",
    "    return idx.to_series().str.slice(0, 12)\n",
    "\n",
    "# standarized patient IDs across all files\n",
    "meth.index = trim_barcode(meth.index)\n",
    "rna.index = trim_barcode(rna.index)\n",
    "mirna.index = trim_barcode(mirna.index)\n",
    "clinical.index = clinical.index.str.upper()\n",
    "clinical.index.name = \"Patient_ID\"\n",
    "\n",
    "# convert all data to numeric, coercing errors to NaN\n",
    "meth = meth.apply(pd.to_numeric, errors='coerce')\n",
    "rna = rna.apply(pd.to_numeric, errors='coerce')\n",
    "mirna = mirna.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# for any duplicate columns in the omics data, we average their values\n",
    "meth = meth.groupby(meth.index).mean()\n",
    "rna = rna.groupby(rna.index).mean()\n",
    "mirna = mirna.groupby(mirna.index).mean()\n",
    "\n",
    "# for any duplicate rows in the clinical data, we keep the first occurrence\n",
    "clinical = clinical[~clinical.index.duplicated(keep='first')]\n",
    "\n",
    "print(f\"\\nMethylation shape: {meth.shape}\")\n",
    "print(f\"RNA shape: {rna.shape}\")\n",
    "print(f\"miRNA shape: {mirna.shape}\")\n",
    "print(f\"Clinical shape: {clinical.shape}\")\n",
    "\n",
    "for df in [meth, rna, mirna]:\n",
    "    df.columns = df.columns.str.replace(r\"\\?\", \"unknown_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"\\|\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(\"-\", \"_\", regex=False)\n",
    "    df.columns = df.columns.str.replace(r\"_+\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.strip(\"_\")\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# to see which pateints are common across all data files\n",
    "common_patients = sorted(list(set(meth.index)&set(rna.index)&set(mirna.index)&set(clinical.index)))\n",
    "\n",
    "print(f\"\\nFound: {len(common_patients)} patients across all data types.\")\n",
    "\n",
    "# subset to only common patients\n",
    "meth_processed = meth.loc[common_patients]\n",
    "rna_processed= rna.loc[common_patients]\n",
    "mirna_processed = mirna.loc[common_patients]\n",
    "clinical_processed = clinical.loc[common_patients]\n",
    "\n",
    "# extract target labels from clinical data\n",
    "targets = clinical_processed['vital_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c562ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mirna_processed.iloc[:3,:5])\n",
    "display(mirna_processed.shape)\n",
    "\n",
    "display(rna_processed.iloc[:3,:5])\n",
    "display(rna_processed.shape)\n",
    "\n",
    "display(meth_processed.iloc[:3,:5])\n",
    "display(meth_processed.shape)\n",
    "\n",
    "display(clinical_processed.iloc[:3,:5])\n",
    "display(clinical_processed.shape)\n",
    "\n",
    "display(targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "# drop unwanted columns from clinical data\n",
    "clinical_processed.drop(columns=[\"Composite Element REF\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "# we transform the methylation beta values to M-values and drop unwanted columns\n",
    "meth_m = meth_processed.drop(columns=[\"Composite Element REF\"], errors=\"ignore\")\n",
    "\n",
    "# convert beta values to M-values using bioneuralnet utility with small epsilon to avoid log(0)\n",
    "meth_m = bnn.utils.beta_to_m(meth_m, eps=1e-6) \n",
    "\n",
    "# lastly we turn the target labels into numerical classes\n",
    "mapping = {\"astrocytoma\": 0, \"oligodendroglioma\": 1, \"oligoastrocytoma\": 2}\n",
    "target_labels = targets.map(mapping).to_frame(name=\"target\")\n",
    "\n",
    "# as a safety check we align the indices once more\n",
    "X_meth = meth_m.loc[common_patients]\n",
    "X_rna = rna_processed.loc[common_patients]\n",
    "X_mirna = mirna_processed.loc[common_patients]\n",
    "Y_labels = target_labels.loc[common_patients]\n",
    "clinical_final = clinical_processed.loc[common_patients]\n",
    "\n",
    "print(f\"\\nDNA_Methylation shape: {X_meth.shape}\")\n",
    "print(f\"RNA shape: {X_rna.shape}\")\n",
    "print(f\"miRNA shape: {X_mirna.shape}\")\n",
    "print(f\"Clinical shape: {clinical_final.shape}\")\n",
    "print(Y_labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643ec13",
   "metadata": {},
   "source": [
    "## Feature Selection Methodology\n",
    "\n",
    "### Supported Methods and Interpretation\n",
    "\n",
    "**BioNeuralNet** provides three techniques for feature selection, allowing for different views of the data's statistical profile:\n",
    "\n",
    "- **Variance Thresholding:** Identifies features with the **highest overall variance** across all samples.\n",
    "\n",
    "- **ANOVA F-test:** Pinpoints features that best **distinguish between the target classes** (KIRC, KIRP, and KICH).\n",
    "\n",
    "- **Random Forest Importance:** Assesses **feature utility** based on its contribution to a predictive non-linear model.\n",
    "\n",
    "### LGG Cohort Selection Strategy\n",
    "\n",
    "A dimensionality reduction step was essential for managing the high-feature-count omics data:\n",
    "\n",
    "- **High-Feature Datasets:** Both DNA Methylation (20,114) and RNA (18,328) required significant feature reduction.\n",
    "\n",
    "- **Filtering Process:** The **top 6,000 features** were initially extracted from the Methylation and RNA datasets using all three methods.\n",
    "\n",
    "- **Final Set:** A consensus set was built by finding the intersection of features selected by the ANOVA F-test and Random Forest Importance, ensuring both statistical relevance and model-based utility.\n",
    "\n",
    "- **Low-Feature Datasets:** The miRNA data (548 features) was passed through **without selection**, as its feature count was already manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "# feature selection\n",
    "meth_highvar = bnn.utils.select_top_k_variance(X_meth, k=6000)\n",
    "rna_highvar = bnn.utils.select_top_k_variance(X_rna, k=6000)\n",
    "\n",
    "meth_af = bnn.utils.top_anova_f_features(X_meth, Y_labels, max_features=6000)\n",
    "rna_af = bnn.utils.top_anova_f_features(X_rna, Y_labels, max_features=6000)\n",
    "\n",
    "meth_rf = bnn.utils.select_top_randomforest(X_meth, Y_labels, top_k=6000)\n",
    "rna_rf = bnn.utils.select_top_randomforest(X_rna, Y_labels, top_k=6000)\n",
    "\n",
    "meth_var_set = set(meth_highvar.columns)\n",
    "meth_anova_set = set(meth_af.columns)\n",
    "meth_rf_set = set(meth_rf.columns)\n",
    "\n",
    "rna_var_set = set(rna_highvar.columns)\n",
    "rna_anova_set = set(rna_af.columns)\n",
    "rna_rf_set = set(rna_rf.columns)\n",
    "\n",
    "meth_inter1 = list(meth_anova_set & meth_var_set)\n",
    "meth_inter2 = list(meth_rf_set & meth_var_set)\n",
    "meth_inter3 = list(meth_anova_set & meth_rf_set)\n",
    "meth_all_three = list(meth_anova_set & meth_var_set & meth_rf_set)\n",
    "\n",
    "rna_inter4 = list(rna_anova_set & rna_var_set)\n",
    "rna_inter5 = list(rna_rf_set & rna_var_set)\n",
    "rna_inter6 = list(rna_anova_set & rna_rf_set)\n",
    "rna_all_three = list(rna_anova_set & rna_var_set & rna_rf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FROM THE 6000 Methylation feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(meth_inter1)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(meth_inter2)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(meth_inter3)} features\")\n",
    "print(f\"All three methods agree on: {len(meth_all_three)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFROM THE 6000 RNA feature selection:\\n\")\n",
    "print(f\"Anova-F & variance selection share: {len(rna_inter4)} features\")\n",
    "print(f\"Random Forest & variance selection share: {len(rna_inter5)} features\")\n",
    "print(f\"Anova-F & Random Forest share: {len(rna_inter6)} features\")\n",
    "print(f\"All three methods agree on: {len(rna_all_three)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ce6f8",
   "metadata": {},
   "source": [
    "## Feature Selection Summary: ANOVA-RF Intersection\n",
    "\n",
    "The chosen strategy for feature selection is based on the **overlap** between features identified by the **ANOVA F-test** and **Random Forest Importance**. This approach offers comprehensive filtering by balancing class-based relevance (ANOVA) with non-linear model importance (Random Forest). The resulting feature sets are considered the most robust for downstream analysis.\n",
    "\n",
    "### Feature Overlap Results\n",
    "\n",
    "The following table details the number of features resulting from the intersection of different selection methods for each omics data type.\n",
    "\n",
    "| Omics Data Type | ANOVA-F & Variance | RF & Variance | ANOVA-F & Random Forest (Selected) | All Three Agree |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Methylation** | 2,704 features | 1,768 features | **1,823 features** | 809 features |\n",
    "| **RNA** | 2,183 features | 1,977 features | **2,127 features** | 763 features |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1934672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meth_selected = X_meth[meth_inter3]\n",
    "X_rna_selected = X_rna[rna_inter6]\n",
    "\n",
    "print(\"\\nFinal Shapes for Modeling\")\n",
    "print(f\"Methylation (X1): {X_meth_selected.shape}\")\n",
    "print(f\"RNA-Seq (X2): {X_rna_selected.shape}\")\n",
    "print(f\"miRNA-Seq (X3): {X_mirna.shape}\")\n",
    "print(f\"Labels (Y): {Y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348ca2a",
   "metadata": {},
   "source": [
    "## Data Availability\n",
    "\n",
    "To facilitate rapid experimentation and reproduction of our results, the fully processed and feature-selected dataset used in this analysis has been made available directly within the package.\n",
    "\n",
    "Users can load this dataset, bypassing all preceding data acquisition, preprocessing, and feature selection steps. This allows users to proceed immediately from this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import bioneuralnet as bnn\n",
    "\n",
    "tgca_lgg = bnn.datasets.DatasetLoader(\"lgg\")\n",
    "display(tgca_lgg.shape)\n",
    "\n",
    "# The dataset is returned as a dictionary. We extract each file independetly based on the name( Key).\n",
    "dna_meth = tgca_lgg[\"meth\"]\n",
    "rna = tgca_lgg[\"rna\"]\n",
    "mirna = tgca_lgg[\"mirna\"]\n",
    "clinical = tgca_lgg[\"clinical\"]\n",
    "target = tgca_lgg[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95296b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_meth = bnn.utils.select_top_k_variance(dna_meth, k=500)\n",
    "rna = bnn.utils.select_top_k_variance(rna, k=500)\n",
    "mirna = bnn.utils.select_top_k_variance(mirna, k=500)\n",
    "\n",
    "print(dna_meth.shape)\n",
    "print(rna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c76e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import preprocess_clinical\n",
    "clinical_for_model = preprocess_clinical(\n",
    "    X=clinical, \n",
    "    top_k=10,\n",
    "    scale=False,\n",
    "    ignore_columns=[\n",
    "        # target-related or outcome-related or irrelevant columns\n",
    "        \"days_to_last_followup\", \n",
    "        \"days_to_death\",\n",
    "        \"date_of_initial_pathologic_diagnosis\",\n",
    "        \"histological_type\"\n",
    "    ]\n",
    ")\n",
    "display(clinical_for_model.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2b14e",
   "metadata": {},
   "source": [
    "## Reproducibility and Seeding\n",
    "\n",
    "To ensure our experimental results are fully reproducible, a single global seed is set at the beginning of the analysis.\n",
    "\n",
    "This utility function propagates the seed to all sources of randomness, including `random`, `numpy`, and `torch` (for both CPU and GPU). Critically, it also configures the PyTorch cuDNN backend to use deterministic algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioneuralnet as bnn\n",
    "\n",
    "SEED = 1883\n",
    "bnn.utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88084af0",
   "metadata": {},
   "source": [
    "## Classification using DPMON: Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f23044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.utils import find_optimal_graph\n",
    "\n",
    "omics_lgg = pd.concat([mirna, dna_meth, rna], axis=1)\n",
    "\n",
    "optimal_graph, best_params, results_df = find_optimal_graph(\n",
    "    omics_data=omics_lgg,\n",
    "    y_labels=target,\n",
    "    methods=['correlation','threshold'],\n",
    "    seed=SEED,\n",
    "    verbose=False,\n",
    "    trials=10,\n",
    "    omics_list=[mirna, dna_meth, rna],\n",
    "    centrality_mode=\"eigenvector\",\n",
    ")\n",
    "display(optimal_graph.iloc[:5,:5])\n",
    "display(best_params)\n",
    "\n",
    "results_df.sort_values(\"score\", ascending=False, inplace=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph analysis: The optimal gaph uses a proxy to evaluate its properties, but for the final output\n",
    "# the graph is built without the target variable. The search only helps to find the best graph parameters..\n",
    "from bioneuralnet.utils import graph_analysis\n",
    "\n",
    "graph_analysis(optimal_graph, graph_name=\"Optimal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GAT_FINAL/lgg\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"Gat_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_lgg,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GAT',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313822d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "\n",
    "\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GCN_FINAL/lgg\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"Gcn_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_lgg,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GCN',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_GIN_FINAL/lgg\")\n",
    "\n",
    "\n",
    "current_output_dir = output_dir_base / \"gin_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_lgg,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'GIN',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b344bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioneuralnet.downstream_task import DPMON\n",
    "output_dir_base = Path(\"/home/vicente/Github/BioNeuralNet/dpmon_results_SAGE_FINAL/lgg\")\n",
    "\n",
    "current_output_dir = output_dir_base / \"sage_best_graph\"\n",
    "current_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dpmon_params_base = {\n",
    "    \"adjacency_matrix\": optimal_graph,\n",
    "    \"omics_list\": omics_lgg,\n",
    "    \"phenotype_data\": target,\n",
    "    \"phenotype_col\": \"target\",\n",
    "    \"clinical_data\": clinical_for_model,\n",
    "    \"model\": 'SAGE',\n",
    "    \"tune\": True, \n",
    "    \"cv\": True,   \n",
    "    \"n_folds\": 5,\n",
    "    'repeat_num': 1,\n",
    "    \"gpu\": True,\n",
    "    \"cuda\": 0,\n",
    "    \"seed\": SEED,\n",
    "    \"output_dir\": current_output_dir\n",
    "}\n",
    "\n",
    "dpmon_tunned = DPMON(**dpmon_params_base)\n",
    "predictions_df, metrics, embeddings = dpmon_tunned.run()\n",
    "graph_metrics = metrics\n",
    "\n",
    "acc_row = graph_metrics.loc[graph_metrics['Metric'] == 'Accuracy'].iloc[0]\n",
    "f1_macro_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Macro'].iloc[0]\n",
    "f1_weighted_row = graph_metrics.loc[graph_metrics['Metric'] == 'F1 Weighted'].iloc[0]\n",
    "recall_row = graph_metrics.loc[graph_metrics['Metric'] == 'Recall'].iloc[0]\n",
    "auc_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUC'].iloc[0]\n",
    "aupr_row = graph_metrics.loc[graph_metrics['Metric'] == 'AUPR'].iloc[0]\n",
    "\n",
    "acc_avg, acc_std = acc_row['Average'], acc_row['StdDev']\n",
    "f1_macro_avg, f1_macro_std = f1_macro_row['Average'], f1_macro_row['StdDev']\n",
    "f1_weighted_avg, f1_weighted_std = f1_weighted_row['Average'], f1_weighted_row['StdDev']\n",
    "recall_avg, recall_std = recall_row['Average'], recall_row['StdDev']\n",
    "auc_avg, auc_std = auc_row['Average'], auc_row['StdDev']\n",
    "aupr_avg, aupr_std = aupr_row['Average'], aupr_row['StdDev']\n",
    "\n",
    "print(f\"Accuracy (Avg +/- Std): {acc_avg:.4f} +/- {acc_std:.4f}\")\n",
    "print(f\"F1 Macro (Avg +/- Std): {f1_macro_avg:.4f}  +/- {f1_macro_std:.4f}\")\n",
    "print(f\"F1 Weighted (Avg +/- Std): {f1_weighted_avg:.4f} +/- {f1_weighted_std:.4f}\")\n",
    "print(f\"Recall: {recall_avg:.4f} +/- {recall_std:.4f}\")\n",
    "print(f\"AUC: {auc_avg:.4f} +/- {auc_std:.4f}\")\n",
    "print(f\"AUPR: {aupr_avg:.4f} +/- {aupr_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00140d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.concat([dna_meth, rna, mirna, clinical_for_model], axis=1)\n",
    "y = target['target']\n",
    "print(f\"Successfully created X matrix with shape: {X.shape}\")\n",
    "print(f\"Successfully created y vector with shape: {y.shape}\")\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(solver='lbfgs', max_iter=1000, penalty=None, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_mlp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MLPClassifier(max_iter=500, early_stopping=True, n_iter_no_change=10, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBClassifier(eval_metric='logloss', tree_method='hist', max_bin=128, random_state=SEED))\n",
    "])\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "params_lr = {'model__penalty': ['l2'], 'model__C': loguniform(1e-4, 1e2)}\n",
    "\n",
    "params_mlp = {\n",
    "    'model__hidden_layer_sizes': [(100,), (100, 50), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': loguniform(1e-5, 1e-1),\n",
    "    'model__learning_rate_init': loguniform(1e-4, 1e-2)\n",
    "}\n",
    "params_xgb = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': loguniform(0.01, 0.3),\n",
    "    'model__max_depth': randint(3, 7),\n",
    "    'model__subsample': [0.8, 1.0], \n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "params_rf = {\n",
    "    'model__n_estimators': randint(100, 300),\n",
    "    'model__max_depth': [10, 20, 30, None],\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 5),\n",
    "    'model__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "params_svm = {\n",
    "    'model__C': loguniform(1e-2, 1e3),\n",
    "    'model__kernel': ['rbf', 'linear'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "params_dt = {\n",
    "    'model__max_depth': randint(3, 15),\n",
    "    'model__min_samples_split': randint(2, 20),\n",
    "    'model__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "models_to_tune = {\n",
    "    \"LogisticRegression\": (pipe_lr, params_lr),\n",
    "    \"SVM\": (pipe_svm, params_svm),\n",
    "    \"MLP\": (pipe_mlp, params_mlp),\n",
    "    \"XGBoost\": (pipe_xgb, params_xgb),\n",
    "    \"RandomForest\": (pipe_rf, params_rf),\n",
    "    \"DecisionTree\": (pipe_dt, params_dt),\n",
    "}\n",
    "\n",
    "all_results = {\n",
    "    \"LogisticRegression\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"MLP\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"XGBoost\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"RandomForest\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"SVM\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "    \"DecisionTree\": {\"acc\": [], \"f1_w\": [], \"f1_m\": [], \"recall\": [], \"auc\": [], \"aupr\": []},\n",
    "}\n",
    "\n",
    "\n",
    "for model_name, (pipeline, param_dist) in models_to_tune.items():\n",
    "    print(f\"Evaluating model with nested CV: {model_name}\")\n",
    "    \n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=SEED)\n",
    "    \n",
    "    # inner folds are for finding the best hyperparameters\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "        X_train_outer, X_test_outer = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        best_score_fold = -np.inf\n",
    "        best_params_fold = None\n",
    "        # May or may not want to set a seed here. A fix seed = same hyperparamters each fold.\n",
    "        # No seed = different hyperparameters each fold. This adds more randomness, and may yield better generalization.\n",
    "        param_sampler = list(ParameterSampler(param_dist, n_iter=20))\n",
    "        \n",
    "        for params in param_sampler:\n",
    "            inner_scores = []\n",
    "            \n",
    "            for inner_train_idx, inner_val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "                X_train_inner = X_train_outer.iloc[inner_train_idx]\n",
    "                X_val_inner = X_train_outer.iloc[inner_val_idx]\n",
    "                y_train_inner = y_train_outer.iloc[inner_train_idx]\n",
    "                y_val_inner = y_train_outer.iloc[inner_val_idx]\n",
    "                \n",
    "                inner_pipeline = clone(pipeline)\n",
    "                inner_pipeline.set_params(**params)\n",
    "                inner_pipeline.fit(X_train_inner, y_train_inner)\n",
    "                \n",
    "                y_val_pred = inner_pipeline.predict(X_val_inner)\n",
    "                score = f1_score(y_val_inner, y_val_pred, average='weighted', zero_division=0)\n",
    "                inner_scores.append(score)\n",
    "            \n",
    "            mean_score = np.mean(inner_scores)\n",
    "            if mean_score > best_score_fold:\n",
    "                best_score_fold = mean_score\n",
    "                best_params_fold = params\n",
    "        \n",
    "        print(f\"Outer fold {fold_idx}: best params (inner CV F1-W={best_score_fold:.4f})\")\n",
    "        print(f\"{best_params_fold}\")\n",
    "        \n",
    "        final_pipeline = clone(pipeline)\n",
    "        final_pipeline.set_params(**best_params_fold)\n",
    "        final_pipeline.fit(X_train_outer, y_train_outer)\n",
    "        \n",
    "        preds = final_pipeline.predict(X_test_outer)\n",
    "        \n",
    "        if hasattr(final_pipeline, \"predict_proba\"):\n",
    "            proba = final_pipeline.predict_proba(X_test_outer)\n",
    "        else:\n",
    "            proba = None\n",
    "        \n",
    "        acc = accuracy_score(y_test_outer, preds)\n",
    "        f1_w = f1_score(y_test_outer, preds, average='weighted', zero_division=0)\n",
    "        f1_m = f1_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_test_outer, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        auc = np.nan\n",
    "        aupr = np.nan\n",
    "        \n",
    "        if proba is not None:\n",
    "            try:\n",
    "                if len(np.unique(y)) == 2:\n",
    "                    auc = roc_auc_score(y_test_outer, proba[:, 1])\n",
    "                    aupr = average_precision_score(y_test_outer, proba[:, 1])\n",
    "                else:\n",
    "                    auc = roc_auc_score(y_test_outer, proba, multi_class='ovr', average='macro')\n",
    "                    y_test_bin = label_binarize(y_test_outer, classes=np.unique(y))\n",
    "                    aupr = average_precision_score(y_test_bin, proba, average='weighted')\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "                aupr = np.nan\n",
    "\n",
    "        print(f\"Fold {fold_idx} results: Acc={acc:.4f}, F1-W={f1_w:.4f}, \"\n",
    "              f\"F1-M={f1_m:.4f}, Recall={recall:.4f}, AUC={auc:.4f}, AUPR={aupr:.4f}\")\n",
    "        \n",
    "        all_results[model_name][\"acc\"].append(acc)\n",
    "        all_results[model_name][\"f1_w\"].append(f1_w)\n",
    "        all_results[model_name][\"f1_m\"].append(f1_m)\n",
    "        all_results[model_name][\"recall\"].append(recall)\n",
    "        all_results[model_name][\"auc\"].append(auc)\n",
    "        all_results[model_name][\"aupr\"].append(aupr)\n",
    "\n",
    "print(\"\\nFINAL BASELINE RESULTS\\n\")\n",
    "for model_name, metrics in all_results.items():\n",
    "    avg_acc = np.mean(metrics[\"acc\"])\n",
    "    std_acc = np.std(metrics[\"acc\"])\n",
    "    avg_f1_w = np.mean(metrics[\"f1_w\"])\n",
    "    std_f1_w = np.std(metrics[\"f1_w\"])\n",
    "    avg_f1_m = np.mean(metrics[\"f1_m\"])\n",
    "    std_f1_m = np.std(metrics[\"f1_m\"])\n",
    "    avg_recall = np.mean(metrics[\"recall\"])\n",
    "    std_recall = np.std(metrics[\"recall\"])\n",
    "    avg_auc = np.nanmean(metrics[\"auc\"])\n",
    "    std_auc = np.nanstd(metrics[\"auc\"])\n",
    "    avg_aupr = np.nanmean(metrics[\"aupr\"])\n",
    "    std_aupr = np.nanstd(metrics[\"aupr\"])\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Accuracy: {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    print(f\"F1 Weighted: {avg_f1_w:.4f} +/- {std_f1_w:.4f}\")\n",
    "    print(f\"F1 Macro: {avg_f1_m:.4f} +/- {std_f1_m:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n",
    "    print(f\"AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "    print(f\"AUPR: {avg_aupr:.4f} +/- {std_aupr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
